{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e17aa471",
   "metadata": {},
   "source": [
    "# Solveur de Jacobi : Modèles de programmation Multi-GPU\n",
    "Ce notebook présente 12 versions progressives d’un solveur de Jacobi 2D. Chaque section explique le modèle ou l’optimisation, compile la version, exécute et collecte les métriques Nsight."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2506cee8",
   "metadata": {},
   "source": [
    "```markdown\n",
    "## Modules Spack à charger\n",
    "\n",
    "Avant de compiler ou d’exécuter les différentes étapes, il est recommandé de charger les modules nécessaires via Spack. \n",
    "Préférablement avant de lancer VSCode ou jupyter\n",
    "Par exemple :\n",
    "\n",
    "```bash\n",
    "spack load nvhpc@24.11\n",
    "spack load cuda@12.6\n",
    "export NVSHMEM_HOME=/apps/2025/manual_install/nvhpc/24.11/Linux_aarch64/24.11/comm_libs/12.6/nvshmem\n",
    "export NCCL_HOME=/apps/2025/manual_install/nvhpc/24.11/Linux_aarch64/24.11/comm_libs/12.6/nccl\n",
    "export LD_LIBRARY_PATH=/apps/2025/manual_install/nvhpc/24.11/Linux_aarch64/24.11/comm_libs/12.6/nccl/lib:$LD_LIBRARY_PATH\n",
    "export LD_LIBRARY_PATH=/apps/2025/manual_install/nvhpc/24.11/Linux_aarch64/24.11/comm_libs/12.6/nvshmem/lib:$LD_LIBRARY_PATH\n",
    "unset OPAL_PREFIX\n",
    "unset PMIX_INSTALL_PREFIX\n",
    "```\n",
    "\n",
    "Adaptez la version de chaque module selon la configuration de votre cluster.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c8dae0a",
   "metadata": {},
   "source": [
    "## etape1_cpu\n",
    "**Description :** Solveur Jacobi CPU de base : implémentation mono-thread. Utile pour valider la correction et les petites tailles de problème ; met en évidence la limite de calcul CPU.\n",
    "\n",
    "**Intérêt :** Baseline : évalue la limite CPU pour établir une référence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e7495f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm -f main *.o main.nsys-rep main.sqlite main.AnalysisSummary.html main.DiagnosticsSummary.html\n",
      "gcc -O2 -o main main.c\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "cd etape1_cpu\n",
    "make clean all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d75f86e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Terminé etape1_cpu\n",
      "CPU time: 15.613598 seconds\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "cd etape1_cpu\n",
    "./main"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7d2f1db",
   "metadata": {},
   "source": [
    "## etape2_cpu_gpu\n",
    "**Description :** 1 CPU + 1 GPU + 1 stream : le CPU pilote le GPU via un unique stream CUDA. Le calcul Jacobi est entièrement délégué au GPU, le CPU ne fait que l’orchestration.\n",
    "\n",
    "**Intérêt :** Met en évidence l'écart de performance CPU vs GPU lorsque la grille est suffisamment grande, dans un contexte réaliste d’utilisation d’un seul GPU et d’un seul stream."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9a70bb1",
   "metadata": {},
   "source": [
    "### Compilation et exécution (1 CPU + 1 GPU + 1 stream)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "61559afe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm -f app *.o main.nsys-rep main.sqlite main.AnalysisSummary.html main.DiagnosticsSummary.html\n",
      "nvcc -O2 -o app main.cu kernel.cu\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "cd etape2_cpu_gpu\n",
    "make clean all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "45d30d45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Terminé etape2_cpu_gpu (1CPU + 1GPU + 1stream)\n",
      "GPU time: 1.560823 seconds\n",
      "Collecting data...\n",
      "Generating '/tmp/nsys-report-73ea.qdstrm'\n",
      "[1/6] [========================100%] main.nsys-rep\n",
      "[2/6] [========================100%] main.sqlite\n",
      "[3/6] Executing 'cuda_api_sum' stats report\n",
      "\n",
      " Time (%)  Total Time (ns)  Num Calls   Avg (ns)     Med (ns)    Min (ns)   Max (ns)   StdDev (ns)           Name         \n",
      " --------  ---------------  ---------  -----------  -----------  ---------  ---------  -----------  ----------------------\n",
      "     71.2        706806976          3  235602325.3  350057600.0    2193280  354556096  202150676.4  cudaMemcpyAsync       \n",
      "     16.2        160747968          1  160747968.0  160747968.0  160747968  160747968          0.0  cudaStreamCreate      \n",
      "      9.9         97992864       1001      97895.0      97984.0       1696     104160       3114.6  cudaStreamSynchronize \n",
      "      2.6         25991168       1000      25991.2       2784.0       2080   23075072     729605.7  cudaLaunchKernel      \n",
      "      0.1           665184          2     332592.0     332592.0     315008     350176      24867.5  cudaMalloc            \n",
      "      0.0           409120          2     204560.0     204560.0     160928     248192      61705.0  cudaFree              \n",
      "      0.0            11392          1      11392.0      11392.0      11392      11392          0.0  cudaStreamDestroy     \n",
      "      0.0             2752          1       2752.0       2752.0       2752       2752          0.0  cuModuleGetLoadingMode\n",
      "\n",
      "[4/6] Executing 'cuda_gpu_kern_sum' stats report\n",
      "\n",
      " Time (%)  Total Time (ns)  Instances  Avg (ns)  Med (ns)  Min (ns)  Max (ns)  StdDev (ns)                   Name                 \n",
      " --------  ---------------  ---------  --------  --------  --------  --------  -----------  --------------------------------------\n",
      "    100.0         92386846       1000   92386.8   92416.0     88416     93760        502.0  jacobi_kernel(double *, double *, int)\n",
      "\n",
      "[5/6] Executing 'cuda_gpu_mem_time_sum' stats report\n",
      "\n",
      " Time (%)  Total Time (ns)  Count   Avg (ns)     Med (ns)    Min (ns)   Max (ns)   StdDev (ns)           Operation          \n",
      " --------  ---------------  -----  -----------  -----------  ---------  ---------  -----------  ----------------------------\n",
      "     99.7        704551093      2  352275546.5  352275546.5  350020315  354530778    3189379.0  [CUDA memcpy Host-to-Device]\n",
      "      0.3          2171200      1    2171200.0    2171200.0    2171200    2171200          0.0  [CUDA memcpy Device-to-Host]\n",
      "\n",
      "[6/6] Executing 'cuda_gpu_mem_size_sum' stats report\n",
      "\n",
      " Total (MB)  Count  Avg (MB)  Med (MB)  Min (MB)  Max (MB)  StdDev (MB)           Operation          \n",
      " ----------  -----  --------  --------  --------  --------  -----------  ----------------------------\n",
      "    268.435      2   134.218   134.218   134.218   134.218        0.000  [CUDA memcpy Host-to-Device]\n",
      "    134.218      1   134.218   134.218   134.218   134.218        0.000  [CUDA memcpy Device-to-Host]\n",
      "\n",
      "Generated:\n",
      "    /gpfs/home/colevalet/Cours/CHPS0904_RENDU/MultiGPU Programming Model/etape2_cpu_gpu/main.nsys-rep\n",
      "    /gpfs/home/colevalet/Cours/CHPS0904_RENDU/MultiGPU Programming Model/etape2_cpu_gpu/main.sqlite\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "cd etape2_cpu_gpu\n",
    "nsys profile -t cuda --stats=true --force-overwrite true -o main ./app"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b20823ca",
   "metadata": {},
   "source": [
    "## etape3_mpi_gpus\n",
    "**Description :** MPI + GPUs : domaine réparti sur plusieurs rangs MPI, chacun pilotant un GPU. Illustrations des défis de mise à l'échelle multi-nœuds et des communications inter-rangs.\n",
    "\n",
    "**Intérêt :** Test de montée en charge inter-nœuds et coût MPI sur cluster multi-GPU.\n",
    "\n",
    "**Step :** \n",
    "- Initialiser MPI, déterminer le rang et le nombre de processus.\n",
    "- Associer chaque rang à un GPU différent.\n",
    "- Diviser la grille entre les rangs (découpage 1D vertical).\n",
    "- Gérer les échanges d’halos entre rangs voisins avec MPI_Sendrecv.\n",
    "- Synchroniser les échanges à chaque itération.\n",
    "- Nettoyer MPI à la fin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0777a424",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm -f app *.o main.nsys-rep main.sqlite main.AnalysisSummary.html main.DiagnosticsSummary.html main.qdstrm\n",
      "/apps/2025/manual_install/nvhpc/24.11/Linux_aarch64/24.11/cuda/12.6/bin/nvcc -O3 -std=c++14 -lcudart -Xcompiler \"-fopenmp\" -I/apps/2025/manual_install/nvhpc/24.11/Linux_aarch64/24.11/cuda/12.6/include -I/apps/2025/manual_install/nvhpc/24.11/Linux_aarch64/24.11/cuda/12.6/include -I/apps/2025/manual_install/nvhpc/24.11/Linux_aarch64/24.11/comm_libs/12.6/hpcx/hpcx-2.20/ompi/include -I/apps/2025/manual_install/nvhpc/24.11/Linux_aarch64/24.11/comm_libs/12.6/nccl/include main.cpp kernel.cu -o app -L/apps/2025/manual_install/nvhpc/24.11/Linux_aarch64/24.11/cuda/12.6/lib64 -L/apps/2025/manual_install/nvhpc/24.11/Linux_aarch64/24.11/comm_libs/12.6/hpcx/hpcx-2.20/ompi/lib -L/apps/2025/manual_install/nvhpc/24.11/Linux_aarch64/24.11/comm_libs/12.6/nccl/lib -lmpi -lnccl -lstdc++ \\\n",
      "\t-Xlinker --no-as-needed\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "cd etape3_mpi_gpus\n",
    "make clean all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "173bcdf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting data...\n",
      "Collecting data...\n",
      "Collecting data...\n",
      "Collecting data...\n",
      "Done: 1000 iters in 4.4008s, norm=1.68569\n",
      "Generating '/tmp/nsys-report-6e4e.qdstrm'\n",
      "Generating '/tmp/nsys-report-6595.qdstrm'\n",
      "Generating '/tmp/nsys-report-a55a.qdstrm'\n",
      "Generating '/tmp/nsys-report-1d6c.qdstrm'\n",
      "[1/7] [========================100%] main.nsys-rep\n",
      "[2/7] [========================100%] main.sqlite\n",
      "[3/7] Executing 'nvtx_sum' stats report\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SKIPPED: No data available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4/7] Executing 'cuda_api_sum' stats report\n",
      "\n",
      " Time (%)  Total Time (ns)  Num Calls  Avg (ns)  Med (ns)  Min (ns)  Max (ns)  StdDev (ns)           Name         \n",
      " --------  ---------------  ---------  --------  --------  --------  --------  -----------  ----------------------\n",
      "     93.4        150371712       5002   30062.3   10240.0      3072    151936      40507.1  cudaMemcpy            \n",
      "      6.1          9886048       1000    9886.0    9344.0      6688    430592      13401.8  cudaLaunchKernel      \n",
      "      0.2           314240          2  157120.0  157120.0     79712    234528     109471.4  cudaFree              \n",
      "      0.2           314112          2  157056.0  157056.0    119200    194912      53536.5  cudaMalloc            \n",
      "      0.1            95072        413     230.2      96.0        32      4608        366.2  cuGetProcAddress_v2   \n",
      "      0.0            46112          2   23056.0   23056.0      4736     41376      25908.4  cudaMemset            \n",
      "      0.0             4128          1    4128.0    4128.0      4128      4128          0.0  cuInit                \n",
      "      0.0              832          1     832.0     832.0       832       832          0.0  cuModuleGetLoadingMode\n",
      "\n",
      "[5/7] Executing 'cuda_gpu_kern_sum' stats report\n",
      "\n",
      " Time (%)  Total Time (ns)  Instances  Avg (ns)  Med (ns)  Min (ns)  Max (ns)  StdDev (ns)                       Name                      \n",
      " --------  ---------------  ---------  --------  --------  --------  --------  -----------  -----------------------------------------------\n",
      "    100.0         14550464       1000   14550.5   14560.0     14272     15488        110.6  jacobi_kernel(const float *, float *, int, int)\n",
      "\n",
      "[6/7] Executing 'cuda_gpu_mem_time_sum' stats report\n",
      "\n",
      " Time (%)  Total Time (ns)  Count  Avg (ns)  Med (ns)  Min (ns)  Max (ns)  StdDev (ns)           Operation          \n",
      " --------  ---------------  -----  --------  --------  --------  --------  -----------  ----------------------------\n",
      "     96.9        104879552   3000   34959.9    2176.0      1600    101984      46708.2  [CUDA memcpy Device-to-Host]\n",
      "      3.1          3354720   2002    1675.7    1568.0      1408     69248       1791.7  [CUDA memcpy Host-to-Device]\n",
      "      0.0            10592      2    5296.0    5296.0      5248      5344         67.9  [CUDA memset]               \n",
      "\n",
      "[7/7] Executing 'cuda_gpu_mem_size_sum' stats report\n",
      "\n",
      " Total (MB)  Count  Avg (MB)  Med (MB)  Min (MB)  Max (MB)  StdDev (MB)           Operation          \n",
      " ----------  -----  --------  --------  --------  --------  -----------  ----------------------------\n",
      "  16842.752   3000     5.614     0.016     0.016    16.810        7.918  [CUDA memcpy Device-to-Host]\n",
      "     66.388   2002     0.033     0.016     0.016    16.810        0.531  [CUDA memcpy Host-to-Device]\n",
      "     33.620      2    16.810    16.810    16.810    16.810        0.000  [CUDA memset]               \n",
      "\n",
      "Generated:\n",
      "    /gpfs/home/colevalet/Cours/CHPS0904_RENDU/MultiGPU Programming Model/etape3_mpi_gpus/main.nsys-rep\n",
      "    /gpfs/home/colevalet/Cours/CHPS0904_RENDU/MultiGPU Programming Model/etape3_mpi_gpus/main.sqlite\n",
      "[1/7] [========================100%] main.nsys-rep\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Importer error status: Importation failed.\n",
      "File is corrupted.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated:\n",
      "    /gpfs/home/colevalet/Cours/CHPS0904_RENDU/MultiGPU Programming Model/etape3_mpi_gpus/main.qdstrm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Importer error status: An unknown error occurred.\n",
      "Dynamic exception type: boost::filesystem::filesystem_error\n",
      "std::exception::what: boost::filesystem::file_size: No such file or directory [system:2]: \"/gpfs/home/colevalet/Cours/CHPS0904_RENDU/MultiGPU Programming Model/etape3_mpi_gpus/main.nsys-rep\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generated:\n",
      "    /gpfs/home/colevalet/Cours/CHPS0904_RENDU/MultiGPU Programming Model/etape3_mpi_gpus/main.qdstrm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Importer error status: An unknown error occurred.\n",
      "Dynamic exception type: boost::filesystem::filesystem_error\n",
      "std::exception::what: boost::filesystem::file_size: No such file or directory [system:2]: \"/gpfs/home/colevalet/Cours/CHPS0904_RENDU/MultiGPU Programming Model/etape3_mpi_gpus/main.nsys-rep\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generated:\n",
      "    /gpfs/home/colevalet/Cours/CHPS0904_RENDU/MultiGPU Programming Model/etape3_mpi_gpus/main.qdstrm\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "cd etape3_mpi_gpus\n",
    "# Nsys ne marche pas tout le temps avec mpirun\n",
    "mpirun -np 4 nsys profile -t mpi,cuda --stats=true --force-overwrite true -o main ./app 1000 4096 4096 1\n",
    "#mpirun -np 4 ./app 1000 4096 4096 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d78f4634",
   "metadata": {},
   "source": [
    "### À partir de quelle taille de matrice le recouvrement communication/calcul devient-il rentable ?\n",
    "\n",
    "Le recouvrement (overlap) communication/calcul devient généralement rentable lorsque :\n",
    "- Le temps de communication (MPI + transferts host/device) devient significatif devant le temps de calcul local.\n",
    "- La partie du calcul qui peut être effectuée pendant la communication (hors bords) est suffisamment grande pour masquer la latence réseau.\n",
    "\n",
    "Pour une grille Jacobi 2D, la taille critique dépend :\n",
    "- De la bande passante et latence réseau,\n",
    "- Du nombre de rangs MPI,\n",
    "- De la rapidité des transferts CUDA Host/Device,\n",
    "- De la puissance du GPU.\n",
    "\n",
    "**Sur la plupart des clusters modernes, le recouvrement commence à être rentable pour des matrices de l’ordre de 16k×16k à 32k×32k (voire plus),** surtout si le nombre de rangs est élevé (≥4) et que la communication devient un vrai goulot d’étranglement.\n",
    "\n",
    "**Pour une matrice 8k×8k,** le calcul local reste souvent dominant, donc le surcoût du overlap (copies, synchronisations) peut masquer le gain.  \n",
    "**Essayez avec 16k×16k ou 32k×32k** pour voir un bénéfice, surtout si vous augmentez le nombre de rangs MPI (et donc la proportion de communication).\n",
    "\n",
    "**Résumé :**  \n",
    "- < 8k×8k : overlap rarement utile  \n",
    "- 16k×16k : commence à être intéressant  \n",
    "- 32k×32k et + : overlap souvent rentable, surtout sur cluster multi-nœuds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b520d22",
   "metadata": {},
   "source": [
    "## etape4_mpi_overlap\n",
    "**Description :** MPI + recouvrement : recouvrements des échanges d’halo non-bloquants avec le calcul Jacobi local. Réduit l'impact de la latence réseau.\n",
    "\n",
    "**Intérêt :** Cache la latence réseau en recouvrant communication et calcul local."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e8382b99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm -f app *.o main.nsys-rep main.sqlite main.AnalysisSummary.html main.DiagnosticsSummary.html main.qdstrm\n",
      "/apps/2025/manual_install/nvhpc/24.11/Linux_aarch64/24.11/cuda/12.6/bin/nvcc -O3 -std=c++14 -lcudart -Xcompiler \"-fopenmp\" -I/apps/2025/manual_install/nvhpc/24.11/Linux_aarch64/24.11/cuda/12.6/include -I/apps/2025/manual_install/nvhpc/24.11/Linux_aarch64/24.11/cuda/12.6/include -I/apps/2025/manual_install/nvhpc/24.11/Linux_aarch64/24.11/comm_libs/12.6/hpcx/hpcx-2.20/ompi/include -I/apps/2025/manual_install/nvhpc/24.11/Linux_aarch64/24.11/comm_libs/12.6/nccl/include main.cpp kernel.cu -o app -L/apps/2025/manual_install/nvhpc/24.11/Linux_aarch64/24.11/cuda/12.6/lib64 -L/apps/2025/manual_install/nvhpc/24.11/Linux_aarch64/24.11/comm_libs/12.6/hpcx/hpcx-2.20/ompi/lib -L/apps/2025/manual_install/nvhpc/24.11/Linux_aarch64/24.11/comm_libs/12.6/nccl/lib -lmpi -lnccl -lstdc++ \\\n",
      "\t-Xlinker --no-as-needed\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "cd etape4_mpi_overlap\n",
    "make clean all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "be3815dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting data...\n",
      "Collecting data...\n",
      "Collecting data...\n",
      "Collecting data...\n",
      "nx=4096 ny=4096 size=4\n",
      "Rang 1: ny_local=1024 offset=1025\n",
      "Rang 2: ny_local=1023 offset=2049\n",
      "Rang 3: ny_local=1023 offset=3072\n",
      "Rang 0: ny_local=1024 offset=1\n",
      "Overlap: 1000 iters en 3.91523 s, norm=1.96709\n",
      "Generating '/tmp/nsys-report-41e7.qdstrm'\n",
      "Generating '/tmp/nsys-report-6f61.qdstrm'\n",
      "Generating '/tmp/nsys-report-ff06.qdstrm'\n",
      "Generating '/tmp/nsys-report-05b4.qdstrm'\n",
      "[1/7] [========================100%] main.nsys-rep\n",
      "[2/7] [========================100%] main.sqliteep\n",
      "[3/7] Executing 'nvtx_sum' stats report\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SKIPPED: No data available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/7] [========================100%] main.nsys-rep[4/7] Executing 'cuda_api_sum' stats report\n",
      "[1/7] [========================100%] main.nsys-rep\n",
      " Time (%)  Total Time (ns)  Num Calls  Avg (ns)   Med (ns)   Min (ns)  Max (ns)  StdDev (ns)              Name             \n",
      " --------  ---------------  ---------  ---------  ---------  --------  --------  -----------  -----------------------------\n",
      "     83.5        206500512       1002   206088.3   205312.0    202272    398016       6861.7  cudaMemcpy                   \n",
      "      5.6         13787808       1000    13787.8    13184.0      8864    433024      13564.0  cudaLaunchKernel             \n",
      "      4.0          9918560          2  4959280.0  4959280.0     68704   9849856    6916318.9  cuMemGetHandleForAddressRange\n",
      "      3.3          8204480       1000     8204.5     8000.0      6656     55360       2456.5  cuMemcpyAsync                \n",
      "      1.6          3936416       2753     1429.9     1376.0       224     28448       1105.8  cuEventQuery                 \n",
      "      1.1          2686976          1  2686976.0  2686976.0   2686976   2686976          0.0  cuMemHostRegister_v2         \n",
      "      0.5          1214656       1000     1214.7     1120.0       640     43712       1727.4  cuEventRecord                \n",
      "      0.2           427136          2   213568.0   213568.0    110048    317088     146399.4  cudaFree                     \n",
      "      0.1           318176          2   159088.0   159088.0    123488    194688      50346.0  cudaMalloc                   \n",
      "      0.0           117024        415      282.0       96.0        32      3232        359.1  cuGetProcAddress_v2          \n",
      "      0.0            45568        129      353.2      320.0        96      2080        196.7  cuEventCreate                \n",
      "      0.0            41984          2    20992.0    20992.0      4992     36992      22627.4  cudaMemset                   \n",
      "      0.0            39872          1    39872.0    39872.0     39872     39872          0.0  cuMemHostUnregister          \n",
      "      0.0            32736        129      253.8      256.0        64      1280        152.4  cuEventDestroy_v2            \n",
      "      0.0            16512          1    16512.0    16512.0     16512     16512          0.0  cuStreamDestroy_v2           \n",
      "      0.0            12480          1    12480.0    12480.0     12480     12480          0.0  cuStreamCreate               \n",
      "      0.0             5856          1     5856.0     5856.0      5856      5856          0.0  cuStreamSynchronize          \n",
      "      0.0             4032          1     4032.0     4032.0      4032      4032          0.0  cuInit                       \n",
      "      0.0              672          1      672.0      672.0       672       672          0.0  cuModuleGetLoadingMode       \n",
      "\n",
      "[5/7] Executing 'cuda_gpu_kern_sum' stats report\n",
      "[1/7] [==================77%       ] main.nsys-rep\n",
      " Time (%)  Total Time (ns)  Instances  Avg (ns)  Med (ns)  Min (ns)  Max (ns)  StdDev (ns)                       Name                      \n",
      " --------  ---------------  ---------  --------  --------  --------  --------  -----------  -----------------------------------------------\n",
      "    100.0         15302304       1000   15302.3   15360.0     14848     15968        221.2  jacobi_kernel(const float *, float *, int, int)\n",
      "\n",
      "[6/7] Executing 'cuda_gpu_mem_time_sum' stats report\n",
      "[1/7] [========================100%] main.nsys-rep\n",
      " Time (%)  Total Time (ns)  Count  Avg (ns)  Med (ns)  Min (ns)  Max (ns)  StdDev (ns)           Operation          \n",
      " --------  ---------------  -----  --------  --------  --------  --------  -----------  ----------------------------\n",
      "     99.0        191974145   1000  191974.1  191808.0    191488    195136        425.4  [CUDA memcpy Device-to-Host]\n",
      "      1.0          1914048   1002    1910.2    1504.0      1472    193760       8557.1  [CUDA memcpy Host-to-Device]\n",
      "      0.0            10208      2    5104.0    5104.0      5024      5184        113.1  [CUDA memset]               \n",
      "\n",
      "[7/7] Executing 'cuda_gpu_mem_size_sum' stats report\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Importer error status: Importation failed.\n",
      "File is corrupted.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated:\n",
      "    /gpfs/home/colevalet/Cours/CHPS0904_RENDU/MultiGPU Programming Model/etape4_mpi_overlap/main.qdstrm\n",
      "\n",
      " Total (MB)  Count  Avg (MB)  Med (MB)  Min (MB)  Max (MB)  StdDev (MB)           Operation          \n",
      " ----------  -----  --------  --------  --------  --------  -----------  ----------------------------\n",
      "  16777.216   1000    16.777    16.777    16.777    16.777        0.000  [CUDA memcpy Device-to-Host]\n",
      "     50.004   1002     0.050     0.016     0.016    16.810        0.750  [CUDA memcpy Host-to-Device]\n",
      "     33.620      2    16.810    16.810    16.810    16.810        0.000  [CUDA memset]               \n",
      "\n",
      "Generated:\n",
      "    /gpfs/home/colevalet/Cours/CHPS0904_RENDU/MultiGPU Programming Model/etape4_mpi_overlap/main.nsys-rep\n",
      "    /gpfs/home/colevalet/Cours/CHPS0904_RENDU/MultiGPU Programming Model/etape4_mpi_overlap/main.sqlite\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Importer error status: An unknown error occurred.\n",
      "Dynamic exception type: boost::filesystem::filesystem_error\n",
      "std::exception::what: boost::filesystem::file_size: No such file or directory [system:2]: \"/gpfs/home/colevalet/Cours/CHPS0904_RENDU/MultiGPU Programming Model/etape4_mpi_overlap/main.nsys-rep\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated:\n",
      "    /gpfs/home/colevalet/Cours/CHPS0904_RENDU/MultiGPU Programming Model/etape4_mpi_overlap/main.qdstrm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Importer error status: An unknown error occurred.\n",
      "Dynamic exception type: boost::filesystem::filesystem_error\n",
      "std::exception::what: boost::filesystem::file_size: No such file or directory [system:2]: \"/gpfs/home/colevalet/Cours/CHPS0904_RENDU/MultiGPU Programming Model/etape4_mpi_overlap/main.nsys-rep\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generated:\n",
      "    /gpfs/home/colevalet/Cours/CHPS0904_RENDU/MultiGPU Programming Model/etape4_mpi_overlap/main.qdstrm\n"
     ]
    }
   ],
   "source": [
    "%%bash \n",
    "cd etape4_mpi_overlap\n",
    "# Nsys ne marche pas tout le temps avec mpirun\n",
    "mpirun -np 4 nsys profile -t mpi,cuda --stats=true --force-overwrite true -o main ./app 1000 4096 4096 1\n",
    "#mpirun -np 4 ./app 1000 4096 4096 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86582246",
   "metadata": {},
   "source": [
    "## etape5_nccl\n",
    "**Description :** NCCL : utilisation de la NVIDIA Collective Communications Library pour les échanges GPU à GPU. Montre les gains via NVLink ou PCIe haute bande passante.\n",
    "\n",
    "**Intérêt :** Exploite automatiquement le topologie NVLink/PCIe pour des échanges GPU efficaces."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b86536f",
   "metadata": {},
   "source": [
    "### Introduction à NCCL\n",
    "\n",
    "NCCL (NVIDIA Collective Communications Library) permet des communications collectives efficaces entre plusieurs GPU, en exploitant la topologie matérielle (NVLink, PCIe).  \n",
    "Dans un contexte Jacobi multi-GPU, NCCL peut être utilisé pour échanger les halos entre GPUs sans repasser par le CPU.\n",
    "\n",
    "**Exemple minimal d'utilisation de NCCL pour un échange entre deux GPU :**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8d614a7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm -f app *.o main.nsys-rep main.sqlite main.AnalysisSummary.html main.DiagnosticsSummary.html main.qdstrm\n",
      "/apps/2025/manual_install/nvhpc/24.11/Linux_aarch64/24.11/cuda/12.6/bin/nvcc -lineinfo -gencode arch=compute_90,code=sm_90 -gencode arch=compute_90,code=compute_90 -std=c++14 -I/apps/2025/manual_install/nvhpc/24.11/Linux_aarch64/24.11/cuda/12.6/include -I/apps/2025/manual_install/nvhpc/24.11/Linux_aarch64/24.11/comm_libs/12.6/hpcx/hpcx-2.20/ompi/include -I/apps/2025/manual_install/nvhpc/24.11/Linux_aarch64/24.11/comm_libs/12.6/nccl/include kernel.cu -c\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/apps/2025/manual_install/nvhpc/24.11/Linux_aarch64/24.11/comm_libs/12.6/hpcx/hpcx-2.20/ompi/bin/mpicxx -DUSE_NVTX -O3 -I/apps/2025/manual_install/nvhpc/24.11/Linux_aarch64/24.11/cuda/12.6/include -I/apps/2025/manual_install/nvhpc/24.11/Linux_aarch64/24.11/comm_libs/12.6/hpcx/hpcx-2.20/ompi/include -I/apps/2025/manual_install/nvhpc/24.11/Linux_aarch64/24.11/comm_libs/12.6/nccl/include -std=c++14 main.cpp kernel.o -L/apps/2025/manual_install/nvhpc/24.11/Linux_aarch64/24.11/cuda/12.6/lib64 -L/apps/2025/manual_install/nvhpc/24.11/Linux_aarch64/24.11/comm_libs/12.6/hpcx/hpcx-2.20/ompi/lib -L/apps/2025/manual_install/nvhpc/24.11/Linux_aarch64/24.11/comm_libs/12.6/nccl/lib -lcudart -ldl -lnccl -o app\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "main.cpp:\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "cd etape5_nccl\n",
    "make clean all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "92d5c968",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting data...\n",
      "Collecting data...\n",
      "Collecting data...\n",
      "Collecting data...\n",
      "NCCL version 2.19.3+cuda12.3\n",
      "Single GPU jacobi relaxation: 1000 iterations on 4096 x 4096 mesh with norm check every 1 iterations\n",
      "    0, 15.998031\n",
      "  100, 0.448892\n",
      "  200, 0.267747\n",
      "  300, 0.197740\n",
      "  400, 0.159443\n",
      "  500, 0.134900\n",
      "  600, 0.117686\n",
      "  700, 0.104841\n",
      "  800, 0.094847\n",
      "  900, 0.086838\n",
      "Jacobi relaxation: 1000 iterations on 4096 x 4096 mesh with norm check every 1 iterations\n",
      "    0, 15.998045\n",
      "  100, 0.448918\n",
      "  200, 0.267779\n",
      "  300, 0.197766\n",
      "  400, 0.159464\n",
      "  500, 0.134924\n",
      "  600, 0.117701\n",
      "  700, 0.104860\n",
      "  800, 0.094871\n",
      "  900, 0.086854\n",
      "Num GPUs: 4.\n",
      "4096x4096: 1 GPU:  29.9511 s, 4 GPUs:  15.3749 s, speedup:     1.95, efficiency:    48.70 \n",
      "Generating '/tmp/nsys-report-7ccc.qdstrm'\n",
      "Generating '/tmp/nsys-report-0d5a.qdstrm'\n",
      "Generating '/tmp/nsys-report-06e5.qdstrm'\n",
      "Generating '/tmp/nsys-report-b7b0.qdstrm'\n",
      "[1/7] [===============65%          ] main.nsys-rep\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Importer error status: Importation failed.\n",
      "File is corrupted.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated:\n",
      "    /gpfs/home/colevalet/Cours/CHPS0904_RENDU/MultiGPU Programming Model/etape5_nccl/main.qdstrm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Importer error status: Importation failed.\n",
      "Import Failed with unexpected exception: /dvs/p4/build/sw/devtools/Agora/Rel/QuadD_Main/QuadD/Common/StreamSections/FileStream.cpp(368): Throw in function void QuadDCommon::FileStream::truncate(std::streamsize)\n",
      "Dynamic exception type: boost::wrapexcept<QuadDCommon::InvalidArgumentException>\n",
      "std::exception::what: InvalidArgumentException\n",
      "[QuadDCommon::tag_message*] = Invalid truncate size.\n",
      "[QuadDCommon::tag_report_file_name*] = \"/gpfs/home/colevalet/Cours/CHPS0904_RENDU/MultiGPU Programming Model/etape5_nccl/main.nsys-rep\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/7] [========================100%] main.nsys-rep\n",
      "Generated:\n",
      "    /gpfs/home/colevalet/Cours/CHPS0904_RENDU/MultiGPU Programming Model/etape5_nccl/main.qdstrm\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Importer error status: An unknown error occurred.\n",
      "Dynamic exception type: boost::filesystem::filesystem_error\n",
      "std::exception::what: boost::filesystem::file_size: No such file or directory [system:2]: \"/gpfs/home/colevalet/Cours/CHPS0904_RENDU/MultiGPU Programming Model/etape5_nccl/main.nsys-rep\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated:\n",
      "    /gpfs/home/colevalet/Cours/CHPS0904_RENDU/MultiGPU Programming Model/etape5_nccl/main.qdstrm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Importer error status: An unknown error occurred.\n",
      "Dynamic exception type: boost::filesystem::filesystem_error\n",
      "std::exception::what: boost::filesystem::file_size: No such file or directory [system:2]: \"/gpfs/home/colevalet/Cours/CHPS0904_RENDU/MultiGPU Programming Model/etape5_nccl/main.nsys-rep\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generated:\n",
      "    /gpfs/home/colevalet/Cours/CHPS0904_RENDU/MultiGPU Programming Model/etape5_nccl/main.qdstrm\n"
     ]
    }
   ],
   "source": [
    "%%bash \n",
    "cd etape5_nccl\n",
    "# Nsys ne marche pas tout le temps avec mpirun\n",
    "NCCL_DEBUG=WARN mpirun -np 4 nsys profile -t mpi,cuda,nvtx --stats=true --force-overwrite true -o main ./app -niter 1000 -nx 4096 -ny 4096 -nccheck 1\n",
    "#NCCL_DEBUG=WARN mpirun -np 4 ./app -niter 1000 -nx 4096 -ny 4096 -nccheck 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ac1f7c0",
   "metadata": {},
   "source": [
    "## etape6_nccl_overlap\n",
    "**Description :** NCCL + recouvrement : superposition des collectifs NCCL avec le calcul sur GPU, cachant le coût de communication.\n",
    "\n",
    "**Intérêt :** Essentiel à forte densité GPU pour maintenir les cœurs occupés."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e02e365a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm -f app *.o main.nsys-rep main.sqlite main.AnalysisSummary.html main.DiagnosticsSummary.html main.qdstrm\n",
      "/apps/2025/manual_install/nvhpc/24.11/Linux_aarch64/24.11/cuda/12.6/bin/nvcc -lineinfo -gencode arch=compute_90,code=sm_90 -gencode arch=compute_90,code=compute_90 -std=c++14 -I/apps/2025/manual_install/nvhpc/24.11/Linux_aarch64/24.11/cuda/12.6/include -I/apps/2025/manual_install/nvhpc/24.11/Linux_aarch64/24.11/comm_libs/12.6/hpcx/hpcx-2.20/ompi/include -I/apps/2025/manual_install/nvhpc/24.11/Linux_aarch64/24.11/comm_libs/12.6/nccl/include kernel.cu -c\n",
      "/apps/2025/manual_install/nvhpc/24.11/Linux_aarch64/24.11/comm_libs/12.6/hpcx/hpcx-2.20/ompi/bin/mpicxx -DUSE_NVTX -O3 -I/apps/2025/manual_install/nvhpc/24.11/Linux_aarch64/24.11/cuda/12.6/include -I/apps/2025/manual_install/nvhpc/24.11/Linux_aarch64/24.11/comm_libs/12.6/hpcx/hpcx-2.20/ompi/include -I/apps/2025/manual_install/nvhpc/24.11/Linux_aarch64/24.11/comm_libs/12.6/nccl/include -std=c++14 main.cpp kernel.o -L/apps/2025/manual_install/nvhpc/24.11/Linux_aarch64/24.11/cuda/12.6/lib64 -L/apps/2025/manual_install/nvhpc/24.11/Linux_aarch64/24.11/comm_libs/12.6/hpcx/hpcx-2.20/ompi/lib -L/apps/2025/manual_install/nvhpc/24.11/Linux_aarch64/24.11/comm_libs/12.6/nccl/lib -lcudart -ldl -lnccl -o app\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "main.cpp:\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "cd etape6_nccl_overlap\n",
    "make clean all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8971d927",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting data...\n",
      "Collecting data...\n",
      "Collecting data...\n",
      "Collecting data...\n",
      "NCCL version 2.19.3+cuda12.3\n",
      "Single GPU jacobi relaxation: 1000 iterations on 4096 x 4096 mesh with norm check every 1 iterations\n",
      "    0, 15.998031\n",
      "  100, 0.448893\n",
      "  200, 0.267746\n",
      "  300, 0.197740\n",
      "  400, 0.159443\n",
      "  500, 0.134900\n",
      "  600, 0.117686\n",
      "  700, 0.104841\n",
      "  800, 0.094847\n",
      "  900, 0.086838\n",
      "Jacobi relaxation: 1000 iterations on 4096 x 4096 mesh with norm check every 1 iterations\n",
      "    0, 15.998046\n",
      "  100, 0.448918\n",
      "  200, 0.267779\n",
      "  300, 0.197766\n",
      "  400, 0.159464\n",
      "  500, 0.134923\n",
      "  600, 0.117701\n",
      "  700, 0.104860\n",
      "  800, 0.094871\n",
      "  900, 0.086854\n",
      "Num GPUs: 4.\n",
      "4096x4096: 1 GPU:  29.8715 s, 4 GPUs:   8.9578 s, speedup:     3.33, efficiency:    83.37 \n",
      "Generating '/tmp/nsys-report-1e2b.qdstrm'\n",
      "Generating '/tmp/nsys-report-bf7c.qdstrm'\n",
      "Generating '/tmp/nsys-report-4357.qdstrm'\n",
      "Generating '/tmp/nsys-report-c351.qdstrm'\n",
      "[1/7] [========================100%] main.nsys-rep\n",
      "[1/7] [==================77%       ] main.nsys-rep\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Export error: /dvs/p4/build/sw/devtools/Agora/Rel/QuadD_Main/QuadD/Common/StreamSections/StreamWithSections.cpp(741): Throw in function void QuadDCommon::parseProtobufFromStream(std::istream&, google::protobuf::Message&)\n",
      "Dynamic exception type: boost::wrapexcept<QuadDCommon::ProtobufParseException>\n",
      "std::exception::what: ProtobufParseException\n",
      "[boost::errinfo_api_function_*] = parseProtobufFromStream\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3/7] Executing 'nvtx_sum' stats report\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "FATAL ERROR: /dvs/p4/build/sw/devtools/Agora/Rel/QuadD_Main/QuadD/Target/Daemon/Agent/OutputFile.cpp(726): Throw in function const boost::filesystem::path& QuadDDaemon::OutputFile::GetPath(QuadDDaemon::Extension) const\n",
      "Dynamic exception type: boost::wrapexcept<QuadDCommon::FileException>\n",
      "std::exception::what: FileException\n",
      "[QuadDCommon::tag_message*] = Output file was never created\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/7] [========================100%] main.nsys-rep\n",
      "[2/7] [===22%                      ] main.sqlite\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Export error: LZ4 decompression failed.\n",
      "FATAL ERROR: /dvs/p4/build/sw/devtools/Agora/Rel/QuadD_Main/QuadD/Target/Daemon/Agent/OutputFile.cpp(726): Throw in function const boost::filesystem::path& QuadDDaemon::OutputFile::GetPath(QuadDDaemon::Extension) const\n",
      "Dynamic exception type: boost::wrapexcept<QuadDCommon::FileException>\n",
      "std::exception::what: FileException\n",
      "[QuadDCommon::tag_message*] = Output file was never created\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3/7] Executing 'nvtx_sum' stats report\n",
      "[1/7] [========================100%] main.nsys-rep\n",
      "[1/7] [========================100%] main.nsys-rep\n",
      "[2/7] [9%                          ] main.sqlite\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Export error: LZ4 decompression failed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2/7] [10%                         ] main.sqlite[3/7] Executing 'nvtx_sum' stats report\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "FATAL ERROR: /dvs/p4/build/sw/devtools/Agora/Rel/QuadD_Main/QuadD/Target/Daemon/Agent/OutputFile.cpp(726): Throw in function const boost::filesystem::path& QuadDDaemon::OutputFile::GetPath(QuadDDaemon::Extension) const\n",
      "Dynamic exception type: boost::wrapexcept<QuadDCommon::FileException>\n",
      "std::exception::what: FileException\n",
      "[QuadDCommon::tag_message*] = Output file was never created\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2/7] [===22%                      ] main.sqlite\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Export error: LZ4 decompression failed.\n",
      "FATAL ERROR: /dvs/p4/build/sw/devtools/Agora/Rel/QuadD_Main/QuadD/Target/Daemon/Agent/OutputFile.cpp(726): Throw in function const boost::filesystem::path& QuadDDaemon::OutputFile::GetPath(QuadDDaemon::Extension) const\n",
      "Dynamic exception type: boost::wrapexcept<QuadDCommon::FileException>\n",
      "std::exception::what: FileException\n",
      "[QuadDCommon::tag_message*] = Output file was never created\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3/7] Executing 'nvtx_sum' stats report\n"
     ]
    }
   ],
   "source": [
    "%%bash \n",
    "cd etape6_nccl_overlap\n",
    "# Nsys ne marche pas tout le temps avec mpirun\n",
    "NCCL_DEBUG=WARN mpirun -np 4 nsys profile -t mpi,cuda,nvtx --stats=true --force-overwrite true -o main ./app -niter 1000 -nx 4096 -ny 4096 -nccheck 1\n",
    "#NCCL_DEBUG=WARN mpirun -np 4 ./app -niter 1000 -nx 4096 -ny 4096 -nccheck 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfd3c561",
   "metadata": {},
   "source": [
    "## etape7_nccl_graphs\n",
    "**Description :** NCCL + CUDA Graphs : capture et relecture des séquences Jacobi/échange pour réduire le surcoût des lancements.\n",
    "\n",
    "**Intérêt :** Réduit l’overhead de lancement grâce aux CUDA Graphs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "65978918",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/apps/2025/manual_install/nvhpc/24.11/Linux_aarch64/24.11/cuda/12.6/bin/nvcc -lineinfo -gencode arch=compute_90,code=sm_90 -gencode arch=compute_90,code=compute_90 -std=c++14 -I/apps/2025/manual_install/nvhpc/24.11/Linux_aarch64/24.11/cuda/12.6/include -I/apps/2025/manual_install/nvhpc/24.11/Linux_aarch64/24.11/comm_libs/12.6/hpcx/hpcx-2.20/ompi/include -I/apps/2025/manual_install/nvhpc/24.11/Linux_aarch64/24.11/comm_libs/12.6/nccl/include kernel.cu -c\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/apps/2025/manual_install/nvhpc/24.11/Linux_aarch64/24.11/comm_libs/12.6/hpcx/hpcx-2.20/ompi/bin/mpicxx -DUSE_NVTX -O3 -I/apps/2025/manual_install/nvhpc/24.11/Linux_aarch64/24.11/cuda/12.6/include -I/apps/2025/manual_install/nvhpc/24.11/Linux_aarch64/24.11/comm_libs/12.6/hpcx/hpcx-2.20/ompi/include -I/apps/2025/manual_install/nvhpc/24.11/Linux_aarch64/24.11/comm_libs/12.6/nccl/include -std=c++14 main.cpp kernel.o -L/apps/2025/manual_install/nvhpc/24.11/Linux_aarch64/24.11/cuda/12.6/lib64 -L/apps/2025/manual_install/nvhpc/24.11/Linux_aarch64/24.11/comm_libs/12.6/hpcx/hpcx-2.20/ompi/lib -L/apps/2025/manual_install/nvhpc/24.11/Linux_aarch64/24.11/comm_libs/12.6/nccl/lib -lcudart -ldl -lnccl -o app\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "main.cpp:\n",
      "\"main.cpp\", line 483: warning: variable \"a_new_reg_handle\" is used before its value is set [used_before_set]\n",
      "          NCCL_CALL(ncclCommDeregister(nccl_comm, a_new_reg_handle));\n",
      "          ^\n",
      "\n",
      "Remark: individual warnings can be suppressed with \"--diag_suppress <warning-name>\"\n",
      "\n",
      "\"main.cpp\", line 484: warning: variable \"a_reg_handle\" is used before its value is set [used_before_set]\n",
      "          NCCL_CALL(ncclCommDeregister(nccl_comm, a_reg_handle));\n",
      "          ^\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%bash \n",
    "cd etape7_nccl_graphs\n",
    "make all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "122ec68d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting data...\n",
      "Collecting data...\n",
      "Collecting data...\n",
      "Collecting data...\n",
      "NCCL version 2.19.3+cuda12.3\n",
      "Single GPU jacobi relaxation: 1000 iterations on 4096 x 4096 mesh with norm check every 1 iterations\n",
      "    0, 15.998032\n",
      "  100, 0.448893\n",
      "  200, 0.267747\n",
      "  300, 0.197740\n",
      "  400, 0.159443\n",
      "  500, 0.134900\n",
      "  600, 0.117686\n",
      "  700, 0.104841\n",
      "  800, 0.094847\n",
      "  900, 0.086838\n",
      "Jacobi relaxation: 1000 iterations on 4096 x 4096 mesh with norm check every 1 iterations\n",
      "    0, 15.998045\n",
      "  100, 0.448918\n",
      "  200, 0.267779\n",
      "  300, 0.197766\n",
      "  400, 0.159464\n",
      "  500, 0.134923\n",
      "  600, 0.117701\n",
      "  700, 0.104860\n",
      "  800, 0.094871\n",
      "  900, 0.086854\n",
      "Num GPUs: 4.\n",
      "4096x4096: 1 GPU:  29.9109 s, 4 GPUs:  20.4265 s, speedup:     1.46, efficiency:    36.61 \n",
      "Generating '/tmp/nsys-report-3428.qdstrm'\n",
      "Generating '/tmp/nsys-report-0d77.qdstrm'\n",
      "Generating '/tmp/nsys-report-c564.qdstrm'\n",
      "Generating '/tmp/nsys-report-da7f.qdstrm'\n",
      "[1/7] [=====================86%    ] main.nsys-rep\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Importer error status: Importation failed.\n",
      "File is corrupted.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/7] [=======================93%  ] main.nsys-repGenerated:\n",
      "    /gpfs/home/colevalet/Cours/CHPS0904_RENDU/MultiGPU Programming Model/etape7_nccl_graphs/main.qdstrm\n",
      "[1/7] [========================100%] main.nsys-rep\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Importer error status: Importation failed.\n",
      "Import Failed with unexpected exception: /dvs/p4/build/sw/devtools/Agora/Rel/QuadD_Main/QuadD/Common/StreamSections/FileStream.cpp(368): Throw in function void QuadDCommon::FileStream::truncate(std::streamsize)\n",
      "Dynamic exception type: boost::wrapexcept<QuadDCommon::InvalidArgumentException>\n",
      "std::exception::what: InvalidArgumentException\n",
      "[QuadDCommon::tag_message*] = Invalid truncate size.\n",
      "[QuadDCommon::tag_report_file_name*] = \"/gpfs/home/colevalet/Cours/CHPS0904_RENDU/MultiGPU Programming Model/etape7_nccl_graphs/main.nsys-rep\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2/7] [=======36%                  ] main.sqlite\n",
      "[2/7] [=========44%                ] main.sqliteGenerated:\n",
      "    /gpfs/home/colevalet/Cours/CHPS0904_RENDU/MultiGPU Programming Model/etape7_nccl_graphs/main.qdstrm\n",
      "[2/7] [===========51%              ] main.sqlite\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Importer error status: An unknown error occurred.\n",
      "Dynamic exception type: boost::filesystem::filesystem_error\n",
      "std::exception::what: boost::filesystem::file_size: No such file or directory [system:2]: \"/gpfs/home/colevalet/Cours/CHPS0904_RENDU/MultiGPU Programming Model/etape7_nccl_graphs/main.nsys-rep\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2/7] [============57%             ] main.sqliteGenerated:\n",
      "    /gpfs/home/colevalet/Cours/CHPS0904_RENDU/MultiGPU Programming Model/etape7_nccl_graphs/main.qdstrm\n",
      "[2/7] [========================100%] main.sqlite\n",
      "[3/7] Executing 'nvtx_sum' stats report\n",
      "\n",
      " Time (%)  Total Time (ns)  Instances    Avg (ns)       Med (ns)      Min (ns)     Max (ns)    StdDev (ns)    Style              Range           \n",
      " --------  ---------------  ---------  -------------  -------------  -----------  -----------  ------------  -------  ---------------------------\n",
      "     96.2      50338335008          2  25169167504.0  25169167504.0  20426919904  29911415104  6706550872.1  PushPop  :Jacobi solve              \n",
      "      3.1       1637318688          1   1637318688.0   1637318688.0   1637318688   1637318688           0.0  PushPop  NCCL:ncclCommInitRank      \n",
      "      0.3        143329856          1    143329856.0    143329856.0    143329856    143329856           0.0  PushPop  :NCCL_Warmup               \n",
      "      0.2        113124320         70      1616061.7          224.0           32    105392256    12601138.0  PushPop  NCCL:ncclGroupEnd          \n",
      "      0.1         43479104          1     43479104.0     43479104.0     43479104     43479104           0.0  PushPop  :Graph warmup              \n",
      "      0.1         38099168          1     38099168.0     38099168.0     38099168     38099168           0.0  PushPop  NCCL:ncclCommDestroy       \n",
      "      0.0         11705376       1004        11658.7         3232.0         1952      8031840      253370.1  PushPop  NCCL:hostStreamPlanCallback\n",
      "      0.0          1225280          1      1225280.0      1225280.0      1225280      1225280           0.0  PushPop  :Build graphs              \n",
      "      0.0            87232         28         3115.4         1456.0          512        43200        7960.2  PushPop  NCCL:ncclRecv              \n",
      "      0.0            28544         28         1019.4          864.0          480         3072         539.4  PushPop  NCCL:ncclSend              \n",
      "      0.0            13952         70          199.3          192.0           32          992         145.1  PushPop  NCCL:ncclGroupStart        \n",
      "\n",
      "[4/7] Executing 'cuda_api_sum' stats report\n",
      "\n",
      " Time (%)  Total Time (ns)  Num Calls   Avg (ns)    Med (ns)   Min (ns)  Max (ns)  StdDev (ns)                     Name                   \n",
      " --------  ---------------  ---------  ----------  ----------  --------  --------  -----------  ------------------------------------------\n",
      "     84.2      39683901792       2021  19635775.3  27089600.0      1504  51727008   10776507.2  cudaStreamSynchronize                     \n",
      "     15.7       7392659584       1004   7363206.8   8073536.0     13120  27732512    2815396.2  cudaGraphLaunch_v10000                    \n",
      "      0.0         16199104       3032      5342.7      5376.0      1312    747072      13588.3  cudaMemcpyAsync                           \n",
      "      0.0         12018144         24    500756.0    251056.0      5408   2895808     813882.0  cudaHostAlloc                             \n",
      "      0.0          9303296       1014      9174.8      8832.0       544    293216       9067.4  cudaLaunchKernel                          \n",
      "      0.0          8107680       1011      8019.5      7712.0       768     75712       2994.6  cudaMemsetAsync                           \n",
      "      0.0          3943232         24    164301.3    111616.0      7296    872352     233330.2  cudaFreeHost                              \n",
      "      0.0          3408640       4040       843.7       544.0       320    199168       3164.6  cudaStreamWaitEvent                       \n",
      "      0.0          2301184       3037       757.7       576.0       352     12928        489.4  cudaEventRecord                           \n",
      "      0.0          1692544         14    120896.0      3072.0      1568   1636608     436275.2  cudaLaunchKernelExC_v11060                \n",
      "      0.0          1177088          6    196181.3    160288.0     79168    441440     132945.6  cudaMalloc                                \n",
      "      0.0           982016          8    122752.0    102912.0     18880    277280      94907.5  cudaFree                                  \n",
      "      0.0           703296         12     58608.0     44016.0     36608    152032      33446.4  cuMemSetAccess                            \n",
      "      0.0           585184         12     48765.3     38064.0     32704     89216      20589.5  cuMemUnmap                                \n",
      "      0.0           553600          2    276800.0    276800.0    133856    419744     202153.3  cudaMemcpy                                \n",
      "      0.0           536096         12     44674.7     35328.0     21920     96704      25136.8  cuMemCreate                               \n",
      "      0.0           324704          6     54117.3     10304.0      3456    267968     105200.4  cudaStreamCreateWithFlags                 \n",
      "      0.0           293056          4     73264.0     65312.0     57792    104640      21913.6  cudaGraphExecDestroy_v10000               \n",
      "      0.0           285824          4     71456.0     65840.0     25632    128512      47957.4  cudaGraphInstantiateWithFlags_v11040      \n",
      "      0.0           217408         24      9058.7      6656.0        32     31264      10112.1  cuMemRelease                              \n",
      "      0.0           200096         12     16674.7     12192.0      8992     40992      10415.5  cuMemMap                                  \n",
      "      0.0           151968        819       185.6        96.0        32      4480        281.9  cuGetProcAddress_v2                       \n",
      "      0.0           114432          4     28608.0     19856.0      5120     69600      30585.5  cudaMemset                                \n",
      "      0.0            87424         11      7947.6      5472.0      4256     24896       5993.4  cudaStreamDestroy                         \n",
      "      0.0            63072        154       409.6       192.0        64      5344        597.8  cudaThreadExchangeStreamCaptureMode_v10010\n",
      "      0.0            56064          4     14016.0      7904.0      6208     34048      13385.1  cudaGraphUpload_v10000                    \n",
      "      0.0            48832         12      4069.3      1600.0       992     16672       5168.4  cuMemAddressReserve                       \n",
      "      0.0            39680          4      9920.0      9568.0      3968     16576       5192.3  cudaDeviceSynchronize                     \n",
      "      0.0            29088          3      9696.0      3616.0      3392     22080      10725.4  cudaStreamCreate                          \n",
      "      0.0            23616         12      1968.0      1168.0       768      5024       1513.9  cuMemAddressFree                          \n",
      "      0.0            21536          4      5384.0      5040.0      2240      9216       3547.3  cudaStreamBeginCapture_v10000             \n",
      "      0.0            21344         29       736.0       672.0        64      2144        426.1  cuGetProcAddress                          \n",
      "      0.0            20608          2     10304.0     10304.0      2624     17984      10861.2  cudaStreamCreateWithPriority              \n",
      "      0.0            20128          4      5032.0      3456.0      2656     10560       3710.5  cudaGraphDestroy_v10000                   \n",
      "      0.0            19232          8      2404.0       720.0       352     10496       3555.2  cudaEventDestroy                          \n",
      "      0.0            18464          4      4616.0       528.0       416     16992       8250.9  cudaGraphAddHostNode_v10000               \n",
      "      0.0            17408          8      2176.0       752.0       352      5984       2300.1  cudaEventCreateWithFlags                  \n",
      "      0.0            14496         12      1208.0       816.0       224      4416       1095.5  cuMemRetainAllocationHandle               \n",
      "      0.0            11840         12       986.7        96.0        64      6400       1903.2  cuMemGetAllocationGranularity             \n",
      "      0.0            10240         18       568.9       288.0       160      3616        861.7  cudaStreamGetCaptureInfo_v2_v11030        \n",
      "      0.0             8288          4      2072.0      1536.0       896      4320       1584.9  cudaStreamEndCapture_v10000               \n",
      "      0.0             6560          3      2186.7      2944.0       512      3104       1452.5  cuInit                                    \n",
      "      0.0             6496         12       541.3       304.0       128      3584        963.3  cudaGraphRetainUserObject_v11030          \n",
      "      0.0             5632          8       704.0       480.0       288      2272        646.1  cudaGraphAddEventRecordNode_v11010        \n",
      "      0.0             5536         12       461.3       128.0        96      3776       1047.0  cudaUserObjectCreate_v11030               \n",
      "      0.0             4704          8       588.0       304.0       128      2880        930.0  cudaGraphAddEventWaitNode_v11010          \n",
      "      0.0             4096          8       512.0       304.0       128      2048        636.6  cudaStreamUpdateCaptureDependencies_v11030\n",
      "      0.0             1152          2       576.0       576.0       160       992        588.3  cuModuleGetLoadingMode                    \n",
      "\n",
      "[5/7] Executing 'cuda_gpu_kern_sum' stats report\n",
      "\n",
      " Time (%)  Total Time (ns)  Instances   Avg (ns)    Med (ns)   Min (ns)  Max (ns)  StdDev (ns)                                             Name                                           \n",
      " --------  ---------------  ---------  ----------  ----------  --------  --------  -----------  ------------------------------------------------------------------------------------------\n",
      "     99.9      29439656480       1000  29439656.5  29439584.0  29437600  29442144        775.6  void jacobi_kernel<(int)32, (int)32>(float *, const float *, float *, int, int, int, bool)\n",
      "      0.1         36026208         10   3602620.8    100864.0     27104  24174752    7933379.8  ncclDevKernel_SendRecv(ncclDevComm *, unsigned long, ncclWork *)                          \n",
      "      0.0             5824          2      2912.0      2912.0      2880      2944         45.3  initialize_boundaries(float *, float *, float, int, int, int, int)                        \n",
      "\n",
      "[6/7] Executing 'cuda_gpu_mem_time_sum' stats report\n",
      "\n",
      " Time (%)  Total Time (ns)  Count  Avg (ns)  Med (ns)  Min (ns)  Max (ns)  StdDev (ns)            Operation           \n",
      " --------  ---------------  -----  --------  --------  --------  --------  -----------  ------------------------------\n",
      "     53.7          3333024   2000    1666.5    1664.0      1472      2144        107.8  [CUDA memcpy Device-to-Device]\n",
      "     32.0          1989728   1002    1985.8    1440.0      1440    396128      12852.9  [CUDA memcpy Device-to-Host]  \n",
      "     13.8           859232   1011     849.9     800.0       768     19840        826.4  [CUDA memset]                 \n",
      "      0.4            26432     30     881.1     800.0       736      1312        166.8  [CUDA memcpy Host-to-Device]  \n",
      "\n",
      "[7/7] Executing 'cuda_gpu_mem_size_sum' stats report\n",
      "\n",
      " Total (MB)  Count  Avg (MB)  Med (MB)  Min (MB)  Max (MB)  StdDev (MB)            Operation           \n",
      " ----------  -----  --------  --------  --------  --------  -----------  ------------------------------\n",
      "    167.822   1011     0.166     0.000     0.000    67.109        3.074  [CUDA memset]                 \n",
      "     83.874   1002     0.084     0.000     0.000    67.109        2.185  [CUDA memcpy Device-to-Host]  \n",
      "     32.768   2000     0.016     0.016     0.016     0.016        0.000  [CUDA memcpy Device-to-Device]\n",
      "      0.012     30     0.000     0.000     0.000     0.008        0.001  [CUDA memcpy Host-to-Device]  \n",
      "\n",
      "Generated:\n",
      "    /gpfs/home/colevalet/Cours/CHPS0904_RENDU/MultiGPU Programming Model/etape7_nccl_graphs/main.nsys-rep\n",
      "    /gpfs/home/colevalet/Cours/CHPS0904_RENDU/MultiGPU Programming Model/etape7_nccl_graphs/main.sqlite\n"
     ]
    }
   ],
   "source": [
    "%%bash \n",
    "cd etape7_nccl_graphs\n",
    "# Nsys ne marche pas tout le temps avec mpirun\n",
    "NCCL_DEBUG=WARN mpirun -np 4 nsys profile -t mpi,cuda,nvtx --stats=true --force-overwrite true -o main ./app -niter 1000 -nx 4096 -ny 4096 -nccheck 1\n",
    "#NCCL_DEBUG=WARN mpirun -np 4 ./app -niter 1000 -nx 4096 -ny 4096 -nccheck 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46c4aaa2",
   "metadata": {},
   "source": [
    "## etape8_nvshmem\n",
    "**Description :** NVSHMEM : modèle PGAS à accès mémoire unilatéral GPU, simplifiant les mises à jour d’halo.\n",
    "\n",
    "**Intérêt :** Simplifie les échanges via modèle PGAS unilatéral."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "44a25a10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/apps/2025/manual_install/nvhpc/24.11/Linux_aarch64/24.11/cuda/12.6/bin/nvcc -Xptxas --optimize-float-atomics -ccbin=mpic++ -dc -Xcompiler -fopenmp -lineinfo -DUSE_NVTX -ldl -gencode arch=compute_90,code=sm_90 -std=c++14 -I/apps/2025/manual_install/nvhpc/24.11/Linux_aarch64/24.11/comm_libs/12.6/nvshmem/include main.cu -c -o main.o\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/apps/2025/manual_install/nvhpc/24.11/Linux_aarch64/24.11/cuda/12.6/bin/nvcc -gencode arch=compute_90,code=sm_90 main.o -o main -ccbin=mpic++ -L/apps/2025/manual_install/nvhpc/24.11/Linux_aarch64/24.11/cuda/12.6/lib64 -L/apps/2025/manual_install/nvhpc/24.11/Linux_aarch64/24.11/comm_libs/12.6/nvshmem/lib -lnvshmem -lcuda -lcudart -ldl -lnvidia-ml \n"
     ]
    }
   ],
   "source": [
    "%%bash \n",
    "cd etape8_nvshmem\n",
    "make all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a90f3875",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting data...\n",
      "Collecting data...\n",
      "Collecting data...\n",
      "Collecting data...\n",
      "Setting environment variable NVSHMEM_SYMMETRIC_SIZE = 36981964\n",
      "NCCL version 2.19.3+cuda12.3\n",
      "NCCL version 2.19.3+cuda12.3\n",
      "NCCL version 2.19.3+cuda12.3\n",
      "NCCL version 2.19.3+cuda12.3\n",
      "Single GPU jacobi relaxation: 1000 iterations on 4096 x 4096 mesh with norm check every 1 iterations\n",
      "    0, 15.994146\n",
      "  100, 0.448816\n",
      "  200, 0.267719\n",
      "  300, 0.197726\n",
      "  400, 0.159431\n",
      "  500, 0.134898\n",
      "  600, 0.117676\n",
      "  700, 0.104837\n",
      "  800, 0.094852\n",
      "  900, 0.086836\n",
      "Jacobi relaxation: 1000 iterations on 4096 x 4096 mesh\n",
      "    0, 15.994146\n",
      "  100, 0.448816\n",
      "  200, 0.267722\n",
      "  300, 0.197726\n",
      "  400, 0.159431\n",
      "  500, 0.134898\n",
      "  600, 0.117676\n",
      "  700, 0.104838\n",
      "  800, 0.094853\n",
      "  900, 0.086836\n",
      "Num GPUs: 4.\n",
      "4096x4096: 1 GPU:   1.9420 s, 4 GPUs:  38.5545 s, speedup:     0.05, efficiency:     1.26 \n",
      "Generating '/tmp/nsys-report-f924.qdstrm'\n",
      "Generating '/tmp/nsys-report-8d3f.qdstrm'\n",
      "Generating '/tmp/nsys-report-6f96.qdstrm'\n",
      "Generating '/tmp/nsys-report-aad2.qdstrm'\n",
      "[1/7] [========================100%] main.nsys-rep\n",
      "[1/7] [===================79%      ] main.nsys-rep\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Export error: /dvs/p4/build/sw/devtools/Agora/Rel/QuadD_Main/QuadD/Common/StreamSections/StreamWithSections.h(179): Throw in function void QuadDCommon::readFromStream(std::istream&, T&) [with T = long int; std::istream = std::basic_istream<char>]\n",
      "Dynamic exception type: boost::wrapexcept<QuadDCommon::ReadStreamException>\n",
      "std::exception::what: ReadStreamException\n",
      "[QuadDAnalysis::tag_report_file_name*] = \"/gpfs/home/colevalet/Cours/CHPS0904_RENDU/MultiGPU Programming Model/etape8_nvshmem/main.nsys-rep\"\n",
      "[boost::errinfo_api_function_*] = parseSectionTable()\n",
      "\n",
      "FATAL ERROR: /dvs/p4/build/sw/devtools/Agora/Rel/QuadD_Main/QuadD/Target/Daemon/Agent/OutputFile.cpp(726): Throw in function const boost::filesystem::path& QuadDDaemon::OutputFile::GetPath(QuadDDaemon::Extension) const\n",
      "Dynamic exception type: boost::wrapexcept<QuadDCommon::FileException>\n",
      "std::exception::what: FileException\n",
      "[QuadDCommon::tag_message*] = Output file was never created\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3/7] Executing 'nvtx_sum' stats report\n",
      "[1/7] [========================100%] main.nsys-rep\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Importer error status: Importation failed.\n",
      "File is corrupted.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated:\n",
      "    /gpfs/home/colevalet/Cours/CHPS0904_RENDU/MultiGPU Programming Model/etape8_nvshmem/main.qdstrm\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Importer error status: An unknown error occurred.\n",
      "Dynamic exception type: boost::filesystem::filesystem_error\n",
      "std::exception::what: boost::filesystem::file_size: No such file or directory [system:2]: \"/gpfs/home/colevalet/Cours/CHPS0904_RENDU/MultiGPU Programming Model/etape8_nvshmem/main.nsys-rep\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated:\n",
      "    /gpfs/home/colevalet/Cours/CHPS0904_RENDU/MultiGPU Programming Model/etape8_nvshmem/main.qdstrm\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Importer error status: An unknown error occurred.\n",
      "Dynamic exception type: boost::filesystem::filesystem_error\n",
      "std::exception::what: boost::filesystem::file_size: No such file or directory [system:2]: \"/gpfs/home/colevalet/Cours/CHPS0904_RENDU/MultiGPU Programming Model/etape8_nvshmem/main.nsys-rep\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated:\n",
      "    /gpfs/home/colevalet/Cours/CHPS0904_RENDU/MultiGPU Programming Model/etape8_nvshmem/main.qdstrm\n"
     ]
    }
   ],
   "source": [
    "%%bash \n",
    "cd etape8_nvshmem\n",
    "# Nsys ne marche pas tout le temps avec mpirun\n",
    "NCCL_DEBUG=WARN mpirun -np 4 nsys profile -t mpi,cuda,nvtx --stats=true --force-overwrite true -o main ./main -niter 1000 -nx 4096 -ny 4096 -nccheck 1\n",
    "#NCCL_DEBUG=WARN mpirun -np 4 ./main -niter 1000 -nx 4096 -ny 4096 -nccheck 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e519399a",
   "metadata": {},
   "source": [
    "**Remarque :**\n",
    "\n",
    "Les versions utilisant LTO (Link-Time Optimization) ne sont pas disponibles ici. En effet, pour que LTO fonctionne avec NVSHMEM, il est impératif que NVSHMEM lui-même soit compilé avec l’option LTO activée. Or, dans notre environnement, NVSHMEM n’a pas été compilé avec cette option, ce qui rend impossible la génération des exécutables LTO pour ces étapes.\n",
    "Résultat : les étapes nécessitant LTO ne peuvent pas être testées dans ce notebook.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ed9b0f5",
   "metadata": {},
   "source": [
    "## etape9_nvshmem_lto\n",
    "**Description :** NVSHMEM + LTO : ajout de l’optimisation link-time pour inliner les fonctions critiques et réduire le coût des appels.\n",
    "\n",
    "**Intérêt :** Optimisation link-time pour inliner les sections critiques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "876db49b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash cd etape9_nvshmem_lt\n",
    "make all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d751833",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash \n",
    "cd etape9_nvshmem_lt\n",
    "nv-nsight-cu-cli --csv --report-file rapport_etape9_nvshmem_lt.csv ./main\n",
    "cat rapport_etape9_nvshmem_lt.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c2bbaef",
   "metadata": {},
   "source": [
    "## etape10_vshmem_neighborhood_lto\n",
    "**Description :** vshmem neighborhood_sync + LTO : synchronisation fine-grain de voisinage et optimisations link-time O2.\n",
    "\n",
    "**Intérêt :** Synchronisation fine et LTO pour boucles serrées."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f613df4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash \n",
    "cd etape10_vshmem_neighborhood_lto\n",
    "make all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e164dcc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash \n",
    "cd etape10_vshmem_neighborhood_lto\n",
    "nv-nsight-cu-cli --csv --report-file rapport_etape10_vshmem_neighborhood_lto.csv ./main \n",
    "cat rapport_etape10_vshmem_neighborhood_lto.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f7c0e44",
   "metadata": {},
   "source": [
    "## etape11_nvshmem_norm_overlap_neighborhood_sync_lto\n",
    "**Description :** Combinaison : NVSHMEM avec recouvrement, synchrone de voisinage, et LTO pour maximiser la concurrence.\n",
    "\n",
    "**Intérêt :** Combinaison des meilleures pratiques pour un binaire ultra-optimisé."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e23cd41",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash cd etape11_nvshmem_norm_overlap_neighborhood_sync_lto\n",
    "make all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d46b00d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash cd etape11_nvshmem_norm_overlap_neighborhood_sync_lto\n",
    "nv-nsight-cu-cli --csv --report-file rapport_etape11_nvshmem_norm_overlap_neighborhood_sync_lto.csv ./main\n",
    "cat rapport_etape11_nvshmem_norm_overlap_neighborhood_sync_lto.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33006f2a",
   "metadata": {},
   "source": [
    "## etape12_nvshmem_norm_overlap_neighborhood_sync_lto_ext1\n",
    "**Description :** Tuning étendu : paramètres ajustables (taille de tuile, ordre de boucles) et hooks de benchmark.\n",
    "\n",
    "**Intérêt :** Ajout de paramètres de tuning et hooks de benchmarking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c846b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash \n",
    "cd etape12_nvshmem_norm_overlap_neighborhood_sync_lto_ext1 \n",
    "make all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86efdc52",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash \n",
    "cd etape12_nvshmem_norm_overlap_neighborhood_sync_lto_ext1 \n",
    "nv-nsight-cu-cli --csv --report-file rapport_etape12_nvshmem_norm_overlap_neighborhood_sync_lto_ext1.csv ./main\n",
    "cat rapport_etape12_nvshmem_norm_overlap_neighborhood_sync_lto_ext1.csv"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Management with OpenACC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This version of the lab is intended for C/C++ programmers. The Fortran version of this lab is available [here](../Fortran/README.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will receive a warning five minutes before the lab instance shuts down. Remember to save your work! If you are about to run out of time, please see the [Post-Lab](#Post-Lab-Summary) section for saving this lab to view offline later.\n",
    "\n",
    "Don't forget to check out additional [OpenACC Resources](https://www.openacc.org/resources) and join our [OpenACC Slack Channel](https://www.openacc.org/community#slack) to share your experience and get more help from the community."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Let's execute the cell below to display information about the GPUs running on the server. To do this, execute the cell block below by giving it focus (clicking on it with your mouse), and hitting Ctrl-Enter, or pressing the play button in the toolbar above.  If all goes well, you should see some output returned below the grey cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Introduction\n",
    "\n",
    "Our goal for this lab is to use the OpenACC Data Directives to properly manage our data.\n",
    "  \n",
    "  \n",
    "  \n",
    "![development_cycle.png](../images/development_cycle.png)\n",
    "\n",
    "This is the OpenACC 3-Step development cycle.\n",
    "\n",
    "**Analyze** your code, and predict where potential parallelism can be uncovered. Use profiler to help understand what is happening in the code, and where parallelism may exist.\n",
    "\n",
    "**Parallelize** your code, starting with the most time consuming parts. Focus on maintaining correct results from your program.\n",
    "\n",
    "**Optimize** your code, focusing on maximizing performance. Performance may not increase all-at-once during early parallelization.\n",
    "\n",
    "We are currently tackling the **parallelize** step. We will include the OpenACC data directive to properly manage data within our parallelized code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Run the Code (With Managed Memory)\n",
    "\n",
    "In the previous lab, we ran our code with CUDA Managed Memory, and achieved a considerable performance boost. However, managed memory is not compatible with all GPUs, and it performs it may performs worsemmer defined, proper memory management. Run the following script, and note the time the program takes to run. We are expecting that our own implementation which we will develop later in this lab will run a little better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jacobi.c:\n",
      "laplace2d.c:\n",
      "calcNext:\n",
      "     36, Generating copy(A[:n*m]) [if not already present]\n",
      "         Generating implicit firstprivate(j,n,m)\n",
      "         Generating NVIDIA GPU code\n",
      "         38, #pragma acc loop gang /* blockIdx.x */\n",
      "             Generating implicit reduction(max:error)\n",
      "         41, #pragma acc loop vector(128) /* threadIdx.x */\n",
      "     36, Generating implicit copy(error) [if not already present]\n",
      "         Generating copy(Anew[:n*m]) [if not already present]\n",
      "     41, Loop is parallelizable\n",
      "swap:\n",
      "     52, Generating copy(Anew[:n*m],A[:n*m]) [if not already present]\n",
      "         Generating implicit firstprivate(j,n,m)\n",
      "         Generating NVIDIA GPU code\n",
      "         54, #pragma acc loop gang /* blockIdx.x */\n",
      "         57, #pragma acc loop vector(128) /* threadIdx.x */\n",
      "     57, Loop is parallelizable\n",
      "Jacobi relaxation Calculation: 4096 x 4096 mesh\n",
      "    0, 0.250000\n",
      "  100, 0.002397\n",
      "  200, 0.001204\n",
      "  300, 0.000804\n",
      "  400, 0.000603\n",
      "  500, 0.000483\n",
      "  600, 0.000403\n",
      "  700, 0.000345\n",
      "  800, 0.000302\n",
      "  900, 0.000269\n",
      " total: 0.285953 s\n"
     ]
    }
   ],
   "source": [
    "!nvc -fast -acc -gpu=mem:managed -gpu:ccnative -Minfo=accel -o laplace_managed jacobi.c laplace2d.c && ./laplace_managed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optional: Analyze the Code\n",
    "\n",
    "If you would like a refresher on the code files that we are working on, you may view both of them using the two links below.\n",
    "\n",
    "[jacobi.c](jacobi.c)  \n",
    "[laplace2d.c](laplace2d.c)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optional: Profile the Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: CUDA tracing has been automatically enabled since it is a prerequisite for tracing OpenACC.\n",
      "Collecting data...\n",
      "Jacobi relaxation Calculation: 4096 x 4096 mesh\n",
      "    0, 0.250000\n",
      "  100, 0.002397\n",
      "  200, 0.001204\n",
      "  300, 0.000804\n",
      "  400, 0.000603\n",
      "  500, 0.000483\n",
      "  600, 0.000403\n",
      "  700, 0.000345\n",
      "  800, 0.000302\n",
      "  900, 0.000269\n",
      " total: 0.419060 s\n",
      "Generating '/tmp/nsys-report-5faf.qdstrm'\n",
      "[1/7] [========================100%] laplace_managed.nsys-rep\n",
      "[2/7] [========================100%] laplace_managed.sqlite\n",
      "[3/7] Executing 'cuda_api_sum' stats report\n",
      "\n",
      " Time (%)  Total Time (ns)  Num Calls  Avg (ns)  Med (ns)  Min (ns)  Max (ns)  StdDev (ns)          Name        \n",
      " --------  ---------------  ---------  --------  --------  --------  --------  -----------  --------------------\n",
      "     92.6        275747264       6000   45957.9    4336.0      1152  34128512     527339.4  cuStreamSynchronize \n",
      "      4.2         12535424       1000   12535.4    9024.0      8288   3137632      98935.0  cuMemcpyDtoHAsync_v2\n",
      "      2.4          7236736       3000    2412.2    2176.0      1376     44704       1355.0  cuLaunchKernel      \n",
      "      0.5          1625568       1000    1625.6    1440.0      1024     23584        974.4  cuMemsetD32Async    \n",
      "      0.1           182752          1  182752.0  182752.0    182752    182752          0.0  cuMemAllocHost_v2   \n",
      "      0.1           178176          1  178176.0  178176.0    178176    178176          0.0  cuModuleLoadDataEx  \n",
      "      0.0           128320          3   42773.3    6560.0      2016    119744      66697.3  cuMemAlloc_v2       \n",
      "      0.0            41216          1   41216.0   41216.0     41216     41216          0.0  cuMemAllocManaged   \n",
      "      0.0             1504          3     501.3     448.0       160       896        370.9  cuCtxSetCurrent     \n",
      "\n",
      "[4/7] Executing 'cuda_gpu_kern_sum' stats report\n",
      "\n",
      " Time (%)  Total Time (ns)  Instances  Avg (ns)  Med (ns)  Min (ns)  Max (ns)  StdDev (ns)                 Name                \n",
      " --------  ---------------  ---------  --------  --------  --------  --------  -----------  -----------------------------------\n",
      "     56.3        124981476       1000  124981.5   90944.0     89504  34121601    1076143.7  _11laplace2d_c_calcNext_36_gpu     \n",
      "     40.3         89555651       1000   89555.7   89504.0     87808     91968        620.5  _11laplace2d_c_swap_52_gpu         \n",
      "      3.4          7558528       1000    7558.5    7520.0      7072      8608        248.9  _11laplace2d_c_calcNext_36_gpu__red\n",
      "\n",
      "[5/7] Executing 'cuda_gpu_mem_time_sum' stats report\n",
      "\n",
      " Time (%)  Total Time (ns)  Count  Avg (ns)  Med (ns)  Min (ns)  Max (ns)  StdDev (ns)               Operation              \n",
      " --------  ---------------  -----  --------  --------  --------  --------  -----------  ------------------------------------\n",
      "     81.3          9514188   2780    3422.4    3327.0      2431      9728        842.8  [CUDA memcpy Unified Host-to-Device]\n",
      "     11.8          1378944   1000    1378.9    1376.0      1344      4512        104.9  [CUDA memcpy Device-to-Host]        \n",
      "      7.0           815808   1000     815.8     800.0       800      1376         40.3  [CUDA memset]                       \n",
      "\n",
      "[6/7] Executing 'cuda_gpu_mem_size_sum' stats report\n",
      "\n",
      " Total (MB)  Count  Avg (MB)  Med (MB)  Min (MB)  Max (MB)  StdDev (MB)               Operation              \n",
      " ----------  -----  --------  --------  --------  --------  -----------  ------------------------------------\n",
      "    268.501   2780     0.097     0.066     0.066     0.983        0.069  [CUDA memcpy Unified Host-to-Device]\n",
      "      0.008   1000     0.000     0.000     0.000     0.000        0.000  [CUDA memcpy Device-to-Host]        \n",
      "      0.008   1000     0.000     0.000     0.000     0.000        0.000  [CUDA memset]                       \n",
      "\n",
      "[7/7] Executing 'openacc_sum' stats report\n",
      "\n",
      " Time (%)  Total Time (ns)  Num Calls  Avg (ns)  Med (ns)  Min (ns)  Max (ns)  StdDev (ns)                Name              \n",
      " --------  ---------------  ---------  --------  --------  --------  --------  -----------  --------------------------------\n",
      "     24.4        175420224       3000   58473.4    5696.0      1600  34130016     741929.3  Wait@laplace2d.c:36             \n",
      "     24.3        174333280       1000  174333.3  107776.0    105568  34173888    1279489.0  Compute Construct@laplace2d.c:36\n",
      "     14.4        103340992       1000  103341.0   97824.0     95648   3059552     101685.5  Compute Construct@laplace2d.c:52\n",
      "     14.1        101093792       2000   50546.9   55920.0      1600   3055104      86851.8  Wait@laplace2d.c:52             \n",
      "      5.8         41393600       2000   20696.8   14880.0      8832   3147616      77042.6  Exit Data@laplace2d.c:36        \n",
      "      5.4         39032128       1000   39032.1   23680.0     11552  13636640     430508.2  Enter Data@laplace2d.c:52       \n",
      "      4.7         33948832       2000   16974.4   13120.0      8064    959968      29940.9  Enter Data@laplace2d.c:36       \n",
      "      3.4         24776096       1000   24776.1   22640.0      8000   4515680     142451.8  Exit Data@laplace2d.c:52        \n",
      "      1.8         12982144       1000   12982.1    9440.0      8640   3138592      98952.9  Enqueue Download@laplace2d.c:47 \n",
      "      0.8          5436064       2000    2718.0    2496.0      1760     45472       1463.7  Enqueue Launch@laplace2d.c:36   \n",
      "      0.4          3138144       1000    3138.1    2880.0      2080     12832       1219.9  Enqueue Launch@laplace2d.c:52   \n",
      "      0.3          2088096       1000    2088.1    1888.0      1376     24128       1069.0  Enqueue Upload@laplace2d.c:36   \n",
      "      0.2          1562112       1000    1562.1    1536.0      1472      3296        136.2  Wait@laplace2d.c:47             \n",
      "      0.0           219936          1  219936.0  219936.0    219936    219936          0.0  Device Init                     \n",
      "      0.0                0          1       0.0       0.0         0         0          0.0  Alloc@laplace2d.c:36            \n",
      "      0.0                0       1000       0.0       0.0         0         0          0.0  Create@laplace2d.c:36           \n",
      "      0.0                0       1000       0.0       0.0         0         0          0.0  Delete@laplace2d.c:47           \n",
      "\n",
      "Generated:\n",
      "    /gpfs/home/colevalet/Cours/CHPS0904_RENDU/OpenACC/module5/English/C/laplace_managed.nsys-rep\n",
      "    /gpfs/home/colevalet/Cours/CHPS0904_RENDU/OpenACC/module5/English/C/laplace_managed.sqlite\n"
     ]
    }
   ],
   "source": [
    "!nsys profile -t openacc --stats=true --force-overwrite true -o laplace_managed ./laplace_managed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check out the profiler's report. Once the profiling run has completed, download and save the report file by holding down <mark>Shift</mark> and <mark>Right-Clicking</mark> [Here](laplace_managed.qdrep) (choose *save link as*), and open it via the GUI. To view the profiler report locally, please see the section on [How to view the report](../../../module2/English/C/README.ipynb#viewreport)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## OpenACC Structured Data Directive\n",
    "\n",
    "The OpenACC data directives allow the programmer to explicitly manage the data on the device (in our case, the GPU). Specifically, the structured data directive will mark a static region of our code as a **data region**.\n",
    "\n",
    "```cpp\n",
    "< Initialize data on host (CPU) >\n",
    "\n",
    "#pragma acc data < data clauses >\n",
    "{\n",
    "\n",
    "    < Code >\n",
    "\n",
    "}\n",
    "```\n",
    "\n",
    "Device memory allocation happens at the beginning of the region, and device memory deallocation happens at the end of the region. Additionally, any data movement from the host to the device (CPU to GPU) happens at the beginning of the region, and any data movement from the device to the host (GPU to CPU) happens at the end of the region. Memory allocation/deallocation and data movement is defined by which clauses the programmer includes. This is a list of the most important data clauses that we can use:\n",
    "\n",
    "**copy** : `copy( A[0:N] )` : Allocates memory on device and copies data from host to device when entering region and copies data back to the host when exiting region  \n",
    "**copyin** : `copyin( A[0:N] )` : Allocates memory on device and copies data from host to device when entering region  \n",
    "**copyout** : `copyout( A[0:N] )` : Allocates memory on device and copies data to the host when exiting region  \n",
    "**create** : `create( A[0:N] )` : Allocates memory on device but does not copy  \n",
    "**present** : `present( A )` : Data is already present on device from another containing data region  \n",
    "\n",
    "All of these data clauses (except for present) will allocate device memory at the beginning of the data region, and deallocate device memory at the end of the data region. And with the exception of create, they will also transfer some amount of data between the host and device.\n",
    "\n",
    "You may also use them to operate on multiple arrays at once, by including those arrays as a comma separated list.\n",
    "\n",
    "```cpp\n",
    "#pragma acc data copy( A[0:N], B[0:M], C[0:Q] )\n",
    "```\n",
    "\n",
    "You may also use more than one data clause at a time.\n",
    "\n",
    "```cpp\n",
    "#pragma acc data create( A[0:N] ) copyin( B[0:M] ) copyout( C[0:Q] )\n",
    "```\n",
    "\n",
    "These clauses can also be used directly with a parallel or kernels directive, because every parallel and kernels directive is surrounded by an **implied data region**.\n",
    "\n",
    "```cpp\n",
    "#pragma acc kernels create(A[0:N]) copyin(B[0:M]) present(C[0:Q])\n",
    "{\n",
    "    < Code that uses A, B, and C >\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encompassing Multiple Compute Regions\n",
    "\n",
    "A single data region can contain any number of parallel/kernels regions. Take the following example:\n",
    "\n",
    "```cpp\n",
    "#pragma acc data copyin(A[0:N], B[0:N]) create(C[0:N])\n",
    "{\n",
    "\n",
    "    #pragma acc parallel loop\n",
    "    for( int i = 0; i < N; i++ )\n",
    "    {\n",
    "        C[i] = A[i] + B[i];\n",
    "    }\n",
    "    \n",
    "    #pragma acc parallel loop\n",
    "    for( int i = 0; i < N; i++ )\n",
    "    {\n",
    "        A[i] = C[i] + B[i];\n",
    "    }\n",
    "\n",
    "}\n",
    "```\n",
    "\n",
    "You may also encompass function calls within the data region:\n",
    "\n",
    "```cpp\n",
    "void copy(int *A, int *B, int N)\n",
    "{\n",
    "    #pragma acc parallel loop copyout(A[0:N]) copyin(B[0:N])\n",
    "    for( int i = 0; i < N; i++ )\n",
    "    {\n",
    "        A[i] = B[i];\n",
    "    }\n",
    "}\n",
    "\n",
    "...\n",
    "\n",
    "#pragma acc data copyout(A[0:N],B[0:N]) copyin(C[0:N])\n",
    "{\n",
    "    copy(A, C, N);\n",
    "    \n",
    "    copy(A, B, N);\n",
    "}\n",
    "```\n",
    "\n",
    "But wouldn't this code now result in my arrays being copied twice, once by the data region and then again by the parallel loop inside the function calls? In fact, the OpenACC runtime is smart enough to handle exactly this case. Data will be copied in only the first time its encountered in a data clause and out only the last time its encountered in a data clause. This allows you to create fully-working directives within your functions and then later *\"hoist\"* the data movement to a higher level without changing your code at all. This is part of incrementally accelerating your code to avoid incorrect results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Array Shaping\n",
    "\n",
    "The *array shape* defines a portion of an array. Take the following example:\n",
    "\n",
    "```cpp\n",
    "int *A = (int*) malloc(N * sizeof(int));\n",
    "\n",
    "#pragma acc data create( A[0:N] )\n",
    "```\n",
    "\n",
    "The array shape is defined as [0:N], this means that the GPU copy will start at index 0, and be of size N. Array shape is of the format **Array[starting_index:size]**. Let's look at an example where we only want a portion of the array.\n",
    "\n",
    "```cpp\n",
    "int *A = (int*) malloc(N * sizeof(int));\n",
    "\n",
    "#pragma acc data create( A[0:N/2] )\n",
    "```\n",
    "\n",
    "In this example, the GPU copy will start at index 0, but will only be half the size of the CPU copy.\n",
    "\n",
    "The shape of multi-dimensional arrays can be defined as follows:\n",
    "\n",
    "```cpp\n",
    "#pragma acc data create( A[0:N][0:M] )\n",
    "```\n",
    "\n",
    "If you do not include a starting index, then 0 is assumed. For example:\n",
    "\n",
    "```cpp\n",
    "#pragma acc data create( A[0:N] )\n",
    "```\n",
    "\n",
    "is equivalent to\n",
    "\n",
    "```cpp\n",
    "#pragma acc data create( A[:N] )\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Host or Device Memory?\n",
    "\n",
    "Here are two loops:\n",
    "\n",
    "```cpp\n",
    "int *A = (int*) malloc(N * sizeof(int));\n",
    "\n",
    "for (int i = 0; i < N; i++ )\n",
    "{\n",
    "    A[i] = 0;\n",
    "}\n",
    "\n",
    "#pragma acc parallel loop\n",
    "for( int i = 0; i < N; i++ )\n",
    "{\n",
    "    A[i] = 1;\n",
    "}\n",
    "```\n",
    "\n",
    "The first loop is not contained within an OpenACC compute region (a compute region is marked by either the parallel or kernels directive). Thus, `A[i]` will access host (CPU) memory.\n",
    "\n",
    "The second loop is preceeded by the *parallel directive*, meaning that it is contained within an OpenACC compute region. `A[i]` in the second loop will access device (GPU) memory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding the Structured Data Directive to our Code\n",
    "\n",
    "Use the following links to edit our laplace code. Add a structured data directive to properly handle the arrays `A` and `Anew`. \n",
    "\n",
    "[jacobi.c](jacobi.c)   \n",
    "[laplace2d.c](laplace2d.c)  \n",
    "\n",
    "Then, run the following script to check your solution. You code should run just as good as (or slightly better) than our managed memory code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jacobi.c:\n",
      "laplace2d.c:\n",
      "calcNext:\n",
      "     36, Generating copy(A[:n*m]) [if not already present]\n",
      "         Generating implicit firstprivate(j,n,m)\n",
      "         Generating NVIDIA GPU code\n",
      "         38, #pragma acc loop gang /* blockIdx.x */\n",
      "             Generating implicit reduction(max:error)\n",
      "         41, #pragma acc loop vector(128) /* threadIdx.x */\n",
      "     36, Generating implicit copy(error) [if not already present]\n",
      "         Generating copy(Anew[:n*m]) [if not already present]\n",
      "     41, Loop is parallelizable\n",
      "swap:\n",
      "     52, Generating copy(Anew[:n*m],A[:n*m]) [if not already present]\n",
      "         Generating implicit firstprivate(j,n,m)\n",
      "         Generating NVIDIA GPU code\n",
      "         54, #pragma acc loop gang /* blockIdx.x */\n",
      "         57, #pragma acc loop vector(128) /* threadIdx.x */\n",
      "     57, Loop is parallelizable\n",
      "Jacobi relaxation Calculation: 4096 x 4096 mesh\n",
      "    0, 0.250000\n",
      "  100, 0.002397\n",
      "  200, 0.001204\n",
      "  300, 0.000804\n",
      "  400, 0.000603\n",
      "  500, 0.000483\n",
      "  600, 0.000403\n",
      "  700, 0.000345\n",
      "  800, 0.000302\n",
      "  900, 0.000269\n",
      " total: 5.450578 s\n"
     ]
    }
   ],
   "source": [
    "!nvc -fast -acc -gpu:ccnative -Minfo=accel -o laplace_structured jacobi.c laplace2d.c && ./laplace_structured"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are feeling stuck, or would like to check your answer, you can view the correct answer with the following link.\n",
    "\n",
    "[jacobi.c](solutions/advanced_data/structured/jacobi.c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optional: Profile the Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: CUDA tracing has been automatically enabled since it is a prerequisite for tracing OpenACC.\n",
      "Collecting data...\n",
      "Jacobi relaxation Calculation: 4096 x 4096 mesh\n",
      "    0, 0.250000\n",
      "  100, 0.002397\n",
      "  200, 0.001204\n",
      "  300, 0.000804\n",
      "  400, 0.000603\n",
      "  500, 0.000483\n",
      "  600, 0.000403\n",
      "  700, 0.000345\n",
      "  800, 0.000302\n",
      "  900, 0.000269\n",
      " total: 5.649524 s\n",
      "Generating '/tmp/nsys-report-eca9.qdstrm'\n",
      "[1/7] [========================100%] laplace_structured.nsys-rep\n",
      "[2/7] [========================100%] laplace_structured.sqlite\n",
      "[3/7] Executing 'cuda_api_sum' stats report\n",
      "\n",
      " Time (%)  Total Time (ns)  Num Calls  Avg (ns)  Med (ns)  Min (ns)  Max (ns)  StdDev (ns)          Name        \n",
      " --------  ---------------  ---------  --------  --------  --------  --------  -----------  --------------------\n",
      "     68.5       3476168480       5000  695233.7  802144.0      9184  23247488     878702.0  cuMemcpyDtoHAsync_v2\n",
      "     27.3       1383405024       4000  345851.3  333504.0    331008  20949088     359882.7  cuMemcpyHtoDAsync_v2\n",
      "      3.9        199313824       8000   24914.2    1280.0      1120    334144      40302.6  cuStreamSynchronize \n",
      "      0.2         10260032       3000    3420.0    2816.0      1696     24096       1784.6  cuLaunchKernel      \n",
      "      0.0          2039200       1000    2039.2    1792.0      1120     10752        814.6  cuMemsetD32Async    \n",
      "      0.0           749888          5  149977.6  120192.0      1568    319200     156160.6  cuMemAlloc_v2       \n",
      "      0.0           179776          1  179776.0  179776.0    179776    179776          0.0  cuMemAllocHost_v2   \n",
      "      0.0           147744          1  147744.0  147744.0    147744    147744          0.0  cuModuleLoadDataEx  \n",
      "      0.0             1376          3     458.7     416.0       160       800        322.1  cuCtxSetCurrent     \n",
      "      0.0             1312          1    1312.0    1312.0      1312      1312          0.0  cuInit              \n",
      "\n",
      "[4/7] Executing 'cuda_gpu_kern_sum' stats report\n",
      "\n",
      " Time (%)  Total Time (ns)  Instances  Avg (ns)  Med (ns)  Min (ns)  Max (ns)  StdDev (ns)                 Name                \n",
      " --------  ---------------  ---------  --------  --------  --------  --------  -----------  -----------------------------------\n",
      "     48.7         87799040       1000   87799.0   87824.0     84768     89728        454.2  _11laplace2d_c_calcNext_36_gpu     \n",
      "     47.1         84937600       1000   84937.6   84928.0     83104     87264        630.7  _11laplace2d_c_swap_52_gpu         \n",
      "      4.2          7515616       1000    7515.6    7488.0      7008      8672        234.7  _11laplace2d_c_calcNext_36_gpu__red\n",
      "\n",
      "[5/7] Executing 'cuda_gpu_mem_time_sum' stats report\n",
      "\n",
      " Time (%)  Total Time (ns)  Count  Avg (ns)  Med (ns)  Min (ns)  Max (ns)  StdDev (ns)           Operation          \n",
      " --------  ---------------  -----  --------  --------  --------  --------  -----------  ----------------------------\n",
      "     70.9       3181697883   5000  636339.6  794784.0      2272    796512     316944.0  [CUDA memcpy Device-to-Host]\n",
      "     29.1       1304629883   4000  326157.5  326144.0    323936    329280        640.9  [CUDA memcpy Host-to-Device]\n",
      "      0.0           806144   1000     806.1     800.0       768      1280         31.2  [CUDA memset]               \n",
      "\n",
      "[6/7] Executing 'cuda_gpu_mem_size_sum' stats report\n",
      "\n",
      " Total (MB)  Count  Avg (MB)  Med (MB)  Min (MB)  Max (MB)  StdDev (MB)           Operation          \n",
      " ----------  -----  --------  --------  --------  --------  -----------  ----------------------------\n",
      " 536870.920   5000   107.374   134.218     0.000   134.218       53.692  [CUDA memcpy Device-to-Host]\n",
      " 536870.912   4000   134.218   134.218   134.218   134.218        0.000  [CUDA memcpy Host-to-Device]\n",
      "      0.008   1000     0.000     0.000     0.000     0.000        0.000  [CUDA memset]               \n",
      "\n",
      "[7/7] Executing 'openacc_sum' stats report\n",
      "\n",
      " Time (%)  Total Time (ns)  Num Calls  Avg (ns)   Med (ns)   Min (ns)  Max (ns)  StdDev (ns)                Name              \n",
      " --------  ---------------  ---------  ---------  ---------  --------  --------  -----------  --------------------------------\n",
      "     17.3       1762088416       2000   881044.2   826224.0     12096  24062016    1308945.8  Exit Data@laplace2d.c:36        \n",
      "     17.2       1753881120       3000   584627.0   802304.0      9504  23248512     898803.0  Enqueue Download@laplace2d.c:47 \n",
      "     16.9       1729750720       1000  1729750.7  1610816.0   1607968  19614304    1158332.5  Exit Data@laplace2d.c:52        \n",
      "     16.9       1724670752       2000   862335.4   803296.0    801888  18799936     820245.1  Enqueue Download@laplace2d.c:61 \n",
      "      6.9        703436736       1000   703436.7   671984.0    667968  21295872     666992.8  Enter Data@laplace2d.c:52       \n",
      "      6.9        702300032       2000   351150.0   348368.0      8320   6774080     392138.8  Enter Data@laplace2d.c:36       \n",
      "      6.8        698410880       2000   349205.4   333920.0    331392  20950336     471489.9  Enqueue Upload@laplace2d.c:52   \n",
      "      6.8        689397888       3000   229799.3   333376.0      1440   6422112     224409.8  Enqueue Upload@laplace2d.c:36   \n",
      "      1.3        134687424       1000   134687.4   105600.0    102816  27913632     879392.9  Compute Construct@laplace2d.c:36\n",
      "      1.0        105384640       3000    35128.2     5760.0      1472    335424      44848.1  Wait@laplace2d.c:36             \n",
      "      0.9         95940928       1000    95940.9    94176.0     90720    329632      14533.9  Compute Construct@laplace2d.c:52\n",
      "      0.9         92026624       2000    46013.3    52880.0      1440    320320      45463.4  Wait@laplace2d.c:52             \n",
      "      0.1          7516544       2000     3758.3     3232.0      2112     25248       1688.5  Enqueue Launch@laplace2d.c:36   \n",
      "      0.0          4305472       1000     4305.5     3456.0      2272     23840       2156.8  Enqueue Launch@laplace2d.c:52   \n",
      "      0.0          3341184       2000     1670.6     1536.0      1440     18208        535.1  Wait@laplace2d.c:47             \n",
      "      0.0          1799136       1000     1799.1     1584.0      1440      4352        467.4  Wait@laplace2d.c:61             \n",
      "      0.0           188032          1   188032.0   188032.0    188032    188032          0.0  Device Init@laplace2d.c:36      \n",
      "      0.0                0          3        0.0        0.0         0         0          0.0  Alloc@laplace2d.c:36            \n",
      "      0.0                0       3000        0.0        0.0         0         0          0.0  Create@laplace2d.c:36           \n",
      "      0.0                0       2000        0.0        0.0         0         0          0.0  Create@laplace2d.c:52           \n",
      "      0.0                0       3000        0.0        0.0         0         0          0.0  Delete@laplace2d.c:47           \n",
      "      0.0                0       2000        0.0        0.0         0         0          0.0  Delete@laplace2d.c:61           \n",
      "\n",
      "Generated:\n",
      "    /gpfs/home/colevalet/Cours/CHPS0904_RENDU/OpenACC/module5/English/C/laplace_structured.nsys-rep\n",
      "    /gpfs/home/colevalet/Cours/CHPS0904_RENDU/OpenACC/module5/English/C/laplace_structured.sqlite\n"
     ]
    }
   ],
   "source": [
    "!nsys profile -t openacc --stats=true --force-overwrite true -o laplace_structured ./laplace_structured"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check out the profiler's report. Once the profiling run has completed, download and save the report file by holding down <mark>Shift</mark> and <mark>Right-Clicking</mark> [Here](laplace_structured.qdrep) (choose *save link as*), and open it via the GUI. To view the profiler report locally, please see the section on [How to view the report](../../../module2/English/C/README.ipynb#viewreport).\n",
    "\n",
    "Take a moment to explore the profiler, and when you're ready, let's zoom in on the very beginning of our profile.\n",
    "\n",
    "![structured.PNG](../images/structured.png)\n",
    "\n",
    "We can see that we have uninterupted computation, and all of our data movement happens at the beginning of the program. This is ideal, because we are avoiding data transers in the middle of our computation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## OpenACC Unstructured Data Directives\n",
    "\n",
    "There are two unstructured data directives:\n",
    "\n",
    "**enter data**: Handles device memory allocation, and copies from the Host to the Device. The two clauses that you may use with `enter data` are `create` for device memory allocation, and `copyin` for allocation, and memory copy.\n",
    "\n",
    "**exit data**: Handles device memory deallocation, and copies from the Device to the Host. The two clauses that you may use with `exit data` are `delete` for device memory deallocation, and `copyout` for deallocation, and memory copy.\n",
    "\n",
    "The unstructured data directives do not mark a \"data region\", because you are able to have multiple `enter data` and `exit data` directives in your code. It is better to think of them purely as memory allocation and deallocation.\n",
    "\n",
    "The largest advantage of using unstructured data directives is their ability to branch across multiple functions. You may allocate your data in one function, and deallocate it in another. We can look at a simple example of that:\n",
    "\n",
    "```cpp\n",
    "int* allocate(int size)\n",
    "{\n",
    "    int *ptr = (int*) malloc(size * sizeof(int));\n",
    "    #pragma acc enter data create(ptr[0:size])\n",
    "    return ptr;\n",
    "}\n",
    "\n",
    "void deallocate(int *ptr)\n",
    "{\n",
    "    #pragma acc exit data delete(ptr)\n",
    "    free(ptr);\n",
    "}\n",
    "\n",
    "int main()\n",
    "{\n",
    "    int *ptr = allocate(100);\n",
    "    \n",
    "    #pragma acc parallel loop\n",
    "    for( int i = 0; i < 100; i++ )\n",
    "    {\n",
    "        ptr[i] = 0;\n",
    "    }\n",
    "    \n",
    "    deallocate(ptr);\n",
    "}\n",
    "```\n",
    "\n",
    "Just like in the above code sample, you must first allocate the CPU copy of the array **before** you can allocate the GPU copy. Also, you must deallocate the GPU of the array **before** you deallocate the CPU copy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding Unstructured Data Directives to our Code\n",
    "\n",
    "We are going to edit our code to use unstructured data directives to handle memory management. First, run the following script to reset your code to how it was before adding the structured data directive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reset Finished\n"
     ]
    }
   ],
   "source": [
    "!cp ./solutions/basic_data/jacobi.c ./jacobi.c && cp ./solutions/basic_data/laplace2d.c ./laplace2d.c && echo \"Reset Finished\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now edit the code to use unstructured data directives. To fully utilize the unstructured data directives, try to get the code working by only altering the **laplace2d.c** code.\n",
    "\n",
    "[jacobi.c](jacobi.c)   \n",
    "[laplace2d.c](laplace2d.c)  \n",
    "\n",
    "Run the following script to check your solution. Your code should run as fast as our structured implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jacobi.c:\n",
      "main:\n",
      "     60, Generating create(Anew[:m*n]) [if not already present]\n",
      "         Generating copyin(A[:m*n]) [if not already present]\n",
      "laplace2d.c:\n",
      "calcNext:\n",
      "     36, Generating copy(A[:n*m]) [if not already present]\n",
      "         Generating implicit firstprivate(j,n,m)\n",
      "         Generating NVIDIA GPU code\n",
      "         38, #pragma acc loop gang /* blockIdx.x */\n",
      "             Generating implicit reduction(max:error)\n",
      "         41, #pragma acc loop vector(128) /* threadIdx.x */\n",
      "     36, Generating implicit copy(error) [if not already present]\n",
      "         Generating copy(Anew[:n*m]) [if not already present]\n",
      "     41, Loop is parallelizable\n",
      "swap:\n",
      "     52, Generating copy(Anew[:n*m],A[:n*m]) [if not already present]\n",
      "         Generating implicit firstprivate(j,n,m)\n",
      "         Generating NVIDIA GPU code\n",
      "         54, #pragma acc loop gang /* blockIdx.x */\n",
      "         57, #pragma acc loop vector(128) /* threadIdx.x */\n",
      "     57, Loop is parallelizable\n",
      "Jacobi relaxation Calculation: 4096 x 4096 mesh\n",
      "    0, 0.250000\n",
      "  100, 0.002397\n",
      "  200, 0.001204\n",
      "  300, 0.000804\n",
      "  400, 0.000603\n",
      "  500, 0.000483\n",
      "  600, 0.000403\n",
      "  700, 0.000345\n",
      "  800, 0.000302\n",
      "  900, 0.000269\n",
      " total: 0.908306 s\n"
     ]
    }
   ],
   "source": [
    "!nvc -fast -acc -gpu=ccnative -Minfo=accel -o laplace_unstructured jacobi.c laplace2d.c && ./laplace_unstructured"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are feeling stuck, or would like to check your answer, you can view the correct answer with the following link.\n",
    "\n",
    "[laplace2d.c](solutions/advanced_data/unstructured/laplace2d.c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optional: Profile the Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: CUDA tracing has been automatically enabled since it is a prerequisite for tracing OpenACC.\n",
      "Collecting data...\n",
      "Jacobi relaxation Calculation: 4096 x 4096 mesh\n",
      "    0, 0.250000\n",
      "  100, 0.002397\n",
      "  200, 0.001204\n",
      "  300, 0.000804\n",
      "  400, 0.000603\n",
      "  500, 0.000483\n",
      "  600, 0.000403\n",
      "  700, 0.000345\n",
      "  800, 0.000302\n",
      "  900, 0.000269\n",
      " total: 0.768380 s\n",
      "Generating '/tmp/nsys-report-0a0a.qdstrm'\n",
      "[1/7] [========================100%] laplace_unstructured.nsys-rep\n",
      "[2/7] [========================100%] laplace_unstructured.sqlite\n",
      "[3/7] Executing 'cuda_api_sum' stats report\n",
      "\n",
      " Time (%)  Total Time (ns)  Num Calls  Avg (ns)  Med (ns)  Min (ns)  Max (ns)  StdDev (ns)          Name        \n",
      " --------  ---------------  ---------  --------  --------  --------  --------  -----------  --------------------\n",
      "     91.2        202453440       6001   33736.6    4032.0      1120    971264      48777.7  cuStreamSynchronize \n",
      "      4.2          9232704       1000    9232.7    8576.0      7936     67744       4973.5  cuMemcpyDtoHAsync_v2\n",
      "      3.4          7504800       3000    2501.6    1824.0      1344   1563296      28525.1  cuLaunchKernel      \n",
      "      0.6          1342016       1000    1342.0    1088.0       864     11648        694.0  cuMemsetD32Async    \n",
      "      0.3           757760          5  151552.0  125824.0      1536    321632     156569.2  cuMemAlloc_v2       \n",
      "      0.2           346560          1  346560.0  346560.0    346560    346560          0.0  cuMemcpyHtoDAsync_v2\n",
      "      0.1           177888          1  177888.0  177888.0    177888    177888          0.0  cuMemAllocHost_v2   \n",
      "      0.1           170528          1  170528.0  170528.0    170528    170528          0.0  cuModuleLoadDataEx  \n",
      "      0.0             1504          3     501.3     448.0       192       864        339.2  cuCtxSetCurrent     \n",
      "      0.0             1216          1    1216.0    1216.0      1216      1216          0.0  cuInit              \n",
      "\n",
      "[4/7] Executing 'cuda_gpu_kern_sum' stats report\n",
      "\n",
      " Time (%)  Total Time (ns)  Instances  Avg (ns)  Med (ns)  Min (ns)  Max (ns)  StdDev (ns)                 Name                \n",
      " --------  ---------------  ---------  --------  --------  --------  --------  -----------  -----------------------------------\n",
      "     48.9         89421502       1000   89421.5   89440.0     85408     91104        454.1  _11laplace2d_c_calcNext_36_gpu     \n",
      "     47.0         86018015       1000   86018.0   85984.0     84128     88640        624.8  _11laplace2d_c_swap_52_gpu         \n",
      "      4.1          7492448       1000    7492.4    7456.0      6976      8576        264.7  _11laplace2d_c_calcNext_36_gpu__red\n",
      "\n",
      "[5/7] Executing 'cuda_gpu_mem_time_sum' stats report\n",
      "\n",
      " Time (%)  Total Time (ns)  Count  Avg (ns)  Med (ns)  Min (ns)  Max (ns)  StdDev (ns)           Operation          \n",
      " --------  ---------------  -----  --------  --------  --------  --------  -----------  ----------------------------\n",
      "     56.3          1477088   1000    1477.1    1472.0      1440      4544        102.8  [CUDA memcpy Device-to-Host]\n",
      "     31.2           817440   1000     817.4     800.0       800      1280         38.8  [CUDA memset]               \n",
      "     12.5           327392      1  327392.0  327392.0    327392    327392          0.0  [CUDA memcpy Host-to-Device]\n",
      "\n",
      "[6/7] Executing 'cuda_gpu_mem_size_sum' stats report\n",
      "\n",
      " Total (MB)  Count  Avg (MB)  Med (MB)  Min (MB)  Max (MB)  StdDev (MB)           Operation          \n",
      " ----------  -----  --------  --------  --------  --------  -----------  ----------------------------\n",
      "    134.218      1   134.218   134.218   134.218   134.218        0.000  [CUDA memcpy Host-to-Device]\n",
      "      0.008   1000     0.000     0.000     0.000     0.000        0.000  [CUDA memcpy Device-to-Host]\n",
      "      0.008   1000     0.000     0.000     0.000     0.000        0.000  [CUDA memset]               \n",
      "\n",
      "[7/7] Executing 'openacc_sum' stats report\n",
      "\n",
      " Time (%)  Total Time (ns)  Num Calls  Avg (ns)   Med (ns)   Min (ns)  Max (ns)  StdDev (ns)                Name              \n",
      " --------  ---------------  ---------  ---------  ---------  --------  --------  -----------  --------------------------------\n",
      "     23.6        108149856       3000    36050.0     5664.0      1408    370656      46136.7  Wait@laplace2d.c:36             \n",
      "     23.6        107839904       1000   107839.9   105664.0    104064   1575680      47364.9  Compute Construct@laplace2d.c:36\n",
      "     21.1         96556000       1000    96556.0    93632.0     91328    976512      47661.2  Compute Construct@laplace2d.c:52\n",
      "     20.7         94840832       2000    47420.4    46672.0      1408    972640      56911.7  Wait@laplace2d.c:52             \n",
      "      2.9         13097728       2000     6548.9     6480.0       416     75648       7245.8  Exit Data@laplace2d.c:36        \n",
      "      2.4         11010944       2000     5505.5     7872.0      1984     38848       3465.9  Enter Data@laplace2d.c:36       \n",
      "      2.1          9662528       1000     9662.5     8960.0      8256     68544       5025.8  Enqueue Download@laplace2d.c:47 \n",
      "      1.4          6197376       2000     3098.7     2176.0      1696   1564448      34943.9  Enqueue Launch@laplace2d.c:36   \n",
      "      0.6          2520896       1000     2520.9     2336.0      1792     34112       1269.2  Enqueue Launch@laplace2d.c:52   \n",
      "      0.5          2180704       1000     2180.7     2112.0      1984      5792        241.1  Enter Data@laplace2d.c:52       \n",
      "      0.4          1736288       1000     1736.3     1504.0      1216     12064        758.6  Enqueue Upload@laplace2d.c:36   \n",
      "      0.3          1556416       1000     1556.4     1504.0      1440      9568        321.3  Wait@laplace2d.c:47             \n",
      "      0.2          1103936          1  1103936.0  1103936.0   1103936   1103936          0.0  Enter Data@jacobi.c:60          \n",
      "      0.1           566848       1000      566.8      480.0       416      3616        293.1  Exit Data@laplace2d.c:52        \n",
      "      0.1           351232          1   351232.0   351232.0    351232    351232          0.0  Enqueue Upload@jacobi.c:60      \n",
      "      0.0           217184          1   217184.0   217184.0    217184    217184          0.0  Device Init@jacobi.c:60         \n",
      "      0.0             4896          1     4896.0     4896.0      4896      4896          0.0  Wait@jacobi.c:60                \n",
      "      0.0             2016          1     2016.0     2016.0      2016      2016          0.0  Exit Data@jacobi.c:60           \n",
      "      0.0                0          2        0.0        0.0         0         0          0.0  Alloc@jacobi.c:60               \n",
      "      0.0                0          1        0.0        0.0         0         0          0.0  Alloc@laplace2d.c:36            \n",
      "      0.0                0          2        0.0        0.0         0         0          0.0  Create@jacobi.c:60              \n",
      "      0.0                0       1000        0.0        0.0         0         0          0.0  Create@laplace2d.c:36           \n",
      "      0.0                0          2        0.0        0.0         0         0          0.0  Delete@jacobi.c:71              \n",
      "      0.0                0       1000        0.0        0.0         0         0          0.0  Delete@laplace2d.c:47           \n",
      "\n",
      "Generated:\n",
      "    /gpfs/home/colevalet/Cours/CHPS0904_RENDU/OpenACC/module5/English/C/laplace_unstructured.nsys-rep\n",
      "    /gpfs/home/colevalet/Cours/CHPS0904_RENDU/OpenACC/module5/English/C/laplace_unstructured.sqlite\n"
     ]
    }
   ],
   "source": [
    "!nsys profile -t openacc --stats=true --force-overwrite true -o laplace_unstructured ./laplace_unstructured"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check out the profiler's report. Once the profiling run has completed, download and save the report file by holding down <mark>Shift</mark> and <mark>Right-Clicking</mark> [Here](laplace_unstructured.qdrep) (choose *save link as*), and open it via the GUI. To view the profiler report locally, please see the section on [How to view the report](../../../module2/English/C/README.ipynb#viewreport).\n",
    "\n",
    "Take a moment to explore the profiler, and when you're ready, let's zoom in on the very beginning of our profile.\n",
    "\n",
    "![unstructured.PNG](../images/unstructured.png)\n",
    "\n",
    "We can see that we have uninterupted computation, and all of our data movement happens at the beginning of the program. This is ideal, because we are avoiding data transers in the middle of our computation. If you also profiled the structured version of the code, you will notice that the profiles are nearly identical. This isn't surprising, since the structured and unstructured approach work very similarly at the hardware level. However, structured data regions may be easier in simple codes, whereas some codes might flow better when using an unstructured approach. It is up to the programmer to determine via analysis and profiling, which to use."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## OpenACC Update Directive\n",
    "\n",
    "When we use the data directives, there exist two places where the programmer can transfer data between the host and the device. For the structured data directive we have the opportunity to transfer data at the beginning and at the end of the region. For the unstructured data directives, we can transfer data when we use the enter data and exit data directives.\n",
    "\n",
    "However, there may be times in your program where you need to transfer data in the middle of a data region, or between an enter data and an exit data. In order to transfer data at those times, we can use the `update` directive. The update directive will explicitly transfer data between the host and the device. The `update` directive has two clauses:\n",
    "\n",
    "**self**: The self clause will transfer data from the device to the host (GPU to CPU)  \n",
    "**device**: The device clause will transfer data from the host to the device (CPU to GPU)\n",
    "\n",
    "The syntax would look like:\n",
    "\n",
    "`#pragma acc update self(A[0:N])`\n",
    "\n",
    "`#pragma acc update device(A[0:N])`\n",
    "\n",
    "All of the array shaping rules apply.\n",
    "\n",
    "As an example, let's create a version of our laplace code where we want to print the array **A** after every 100 iterations of our loop. The code will look like this:\n",
    "\n",
    "```cpp\n",
    "#pragma acc data copyin( A[:m*n],Anew[:m*n] )\n",
    "{\n",
    "    while ( error > tol && iter < iter_max )\n",
    "    {\n",
    "        error = calcNext(A, Anew, m, n);\n",
    "        swap(A, Anew, m, n);\n",
    "        \n",
    "        if(iter % 100 == 0)\n",
    "        {\n",
    "            printf(\"%5d, %0.6f\\n\", iter, error);\n",
    "            for( int i = 0; i < n; i++ )\n",
    "            {\n",
    "                for( int j = 0; j < m; j++ )\n",
    "                {\n",
    "                    printf(\"%0.2f \", A[i+j*m]);\n",
    "                }\n",
    "                printf(\"\\n\");\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        iter++;\n",
    "\n",
    "    }\n",
    "}\n",
    "```\n",
    "\n",
    "Let's run this code (on a very small data set, so that we don't overload the console by printing thousands of numbers)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./update/jacobi.c:\n",
      "main:\n",
      "     60, Generating copyin(Anew[:m*n],A[:m*n]) [if not already present]\n",
      "./update/laplace2d.c:\n",
      "calcNext:\n",
      "     36, Generating copy(A[:n*m]) [if not already present]\n",
      "         Generating implicit firstprivate(j,n,m)\n",
      "         Generating NVIDIA GPU code\n",
      "         38, #pragma acc loop gang /* blockIdx.x */\n",
      "             Generating implicit reduction(max:error)\n",
      "         41, #pragma acc loop vector(128) /* threadIdx.x */\n",
      "     36, Generating implicit copy(error) [if not already present]\n",
      "         Generating copy(Anew[:n*m]) [if not already present]\n",
      "     41, Loop is parallelizable\n",
      "swap:\n",
      "     52, Generating copy(Anew[:n*m],A[:n*m]) [if not already present]\n",
      "         Generating implicit firstprivate(j,n,m)\n",
      "         Generating NVIDIA GPU code\n",
      "         54, #pragma acc loop gang /* blockIdx.x */\n",
      "         57, #pragma acc loop vector(128) /* threadIdx.x */\n",
      "     57, Loop is parallelizable\n",
      "Jacobi relaxation Calculation: 10 x 10 mesh\n",
      "    0, 0.250000\n",
      "1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 \n",
      "0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 \n",
      "0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 \n",
      "0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 \n",
      "0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 \n",
      "0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 \n",
      "0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 \n",
      "0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 \n",
      "0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 \n",
      "0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 \n",
      "  100, 0.000046\n",
      "1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 \n",
      "0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 \n",
      "0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 \n",
      "0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 \n",
      "0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 \n",
      "0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 \n",
      "0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 \n",
      "0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 \n",
      "0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 \n",
      "0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 \n",
      " total: 0.703811 s\n"
     ]
    }
   ],
   "source": [
    "!nvc -fast -acc -gpu=ccnative -Minfo=accel -o laplace_no_update ./update/jacobi.c ./update/laplace2d.c && ./laplace_no_update 10 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the array is not changing. This is because the host copy of `A` is not being **updated** between loop iterations. Let's add the update directive, and see how the output changes.\n",
    "\n",
    "```cpp\n",
    "#pragma acc data copyin( A[:m*n],Anew[:m*n] )\n",
    "{\n",
    "    while ( error > tol && iter < iter_max )\n",
    "    {\n",
    "        error = calcNext(A, Anew, m, n);\n",
    "        swap(A, Anew, m, n);\n",
    "        \n",
    "        if(iter % 100 == 0)\n",
    "        {\n",
    "            printf(\"%5d, %0.6f\\n\", iter, error);\n",
    "            \n",
    "            #pragma acc update self(A[0:m*n])\n",
    "            \n",
    "            for( int i = 0; i < n; i++ )\n",
    "            {\n",
    "                for( int j = 0; j < m; j++ )\n",
    "                {\n",
    "                    printf(\"%0.2f \", A[i+j*m]);\n",
    "                }\n",
    "                printf(\"\\n\");\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        iter++;\n",
    "\n",
    "    }\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./update/solution/jacobi.c:\n",
      "main:\n",
      "     60, Generating copyin(A[:m*n],Anew[:m*n]) [if not already present]\n",
      "     68, Generating update self(A[:m*n])\n",
      "./update/solution/laplace2d.c:\n",
      "calcNext:\n",
      "     36, Generating copy(A[:n*m]) [if not already present]\n",
      "         Generating implicit firstprivate(j,n,m)\n",
      "         Generating NVIDIA GPU code\n",
      "         38, #pragma acc loop gang /* blockIdx.x */\n",
      "             Generating implicit reduction(max:error)\n",
      "         41, #pragma acc loop vector(128) /* threadIdx.x */\n",
      "     36, Generating implicit copy(error) [if not already present]\n",
      "         Generating copy(Anew[:n*m]) [if not already present]\n",
      "     41, Loop is parallelizable\n",
      "swap:\n",
      "     52, Generating copy(Anew[:n*m],A[:n*m]) [if not already present]\n",
      "         Generating implicit firstprivate(j,n,m)\n",
      "         Generating NVIDIA GPU code\n",
      "         54, #pragma acc loop gang /* blockIdx.x */\n",
      "         57, #pragma acc loop vector(128) /* threadIdx.x */\n",
      "     57, Loop is parallelizable\n",
      "Jacobi relaxation Calculation: 10 x 10 mesh\n",
      "    0, 0.250000\n",
      "1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 \n",
      "0.00 0.25 0.25 0.25 0.25 0.25 0.25 0.25 0.25 0.00 \n",
      "0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 \n",
      "0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 \n",
      "0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 \n",
      "0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 \n",
      "0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 \n",
      "0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 \n",
      "0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 \n",
      "0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 \n",
      "  100, 0.000046\n",
      "1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 1.00 \n",
      "0.00 0.49 0.67 0.74 0.77 0.77 0.74 0.67 0.49 0.00 \n",
      "0.00 0.28 0.45 0.54 0.58 0.58 0.54 0.45 0.28 0.00 \n",
      "0.00 0.17 0.30 0.38 0.42 0.42 0.38 0.30 0.17 0.00 \n",
      "0.00 0.11 0.20 0.26 0.29 0.29 0.26 0.20 0.11 0.00 \n",
      "0.00 0.07 0.14 0.18 0.20 0.20 0.18 0.14 0.07 0.00 \n",
      "0.00 0.05 0.09 0.12 0.14 0.14 0.12 0.09 0.05 0.00 \n",
      "0.00 0.03 0.05 0.07 0.08 0.08 0.07 0.05 0.03 0.00 \n",
      "0.00 0.01 0.03 0.03 0.04 0.04 0.03 0.03 0.01 0.00 \n",
      "0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 \n",
      " total: 0.696870 s\n"
     ]
    }
   ],
   "source": [
    "!nvc -fast -acc -gpu=ccnative -Minfo=accel -o laplace_update ./update/solution/jacobi.c ./update/solution/laplace2d.c && ./laplace_update 10 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Conclusion\n",
    "\n",
    "Relying on managed memory to handle data management can reduce the effort the programmer needs to parallelize their code, however, not all GPUs work with managed memory, and it is also lower performance than using explicit data management. OpenACC gives the programmer two main ways to handle data management, structured and unstructured data directives. By using these, the programmer is able to minimize the number of data transfers needed in their program."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Bonus Task\n",
    "\n",
    "If you would like some additional lessons on using OpenACC, there is an Introduction to OpenACC video series available from the OpenACC YouTube page. The fifth video in the series covers a lot of the content that was covered in this lab.  \n",
    "\n",
    "[Introduction to Parallel Programming with OpenACC - Part 5](https://youtu.be/0zTX7-CPvV8)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Post-Lab Summary\n",
    "\n",
    "If you would like to download this lab for later viewing, it is recommended you go to your browsers File menu (not the Jupyter notebook file menu) and save the complete web page.  This will ensure the images are copied down as well.\n",
    "\n",
    "You can also execute the following cell block to create a zip-file of the files you've been working on, and download it with the link below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "rm -f openacc_files.zip\n",
    "zip -r openacc_files.zip *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**After** executing the above zip command, you should be able to download and save the zip file by holding down <mark>Shift</mark> and <mark>Right-Clicking</mark> [Here](openacc_files.zip)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Licensing\n",
    "This material is released by NVIDIA Corporation under the Creative Commons Attribution 4.0 International (CC BY 4.0)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
